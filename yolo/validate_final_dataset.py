#!/usr/bin/env python3
"""
ìµœì¢… ë°ì´í„°ì…‹ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
- íŒŒì¼ ë¬´ê²°ì„± í™•ì¸
- ë¼ë²¨ í˜•ì‹ ê²€ì¦
- í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
- í•™ìŠµ ì¤€ë¹„ ìƒíƒœ ì ê²€
"""

import os
import yaml
from pathlib import Path
from collections import defaultdict

class DatasetValidator:
    def __init__(self):
        self.dataset_dir = Path("/home/sys1041/work_project/data/processed/final_balanced_pcb_model")
        self.data_yaml = self.dataset_dir / "data.yaml"
        self.errors = []
        self.warnings = []

    def load_config(self):
        """data.yaml ë¡œë“œ"""
        print("="*80)
        print("1. data.yaml ì„¤ì • í™•ì¸")
        print("="*80)

        if not self.data_yaml.exists():
            self.errors.append(f"âŒ data.yaml íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.data_yaml}")
            return None

        with open(self.data_yaml, 'r') as f:
            config = yaml.safe_load(f)

        print(f"\nâœ… data.yaml ë¡œë“œ ì„±ê³µ")
        print(f"  ê²½ë¡œ: {config.get('path', 'N/A')}")
        print(f"  í´ë˜ìŠ¤ ìˆ˜: {config.get('nc', 'N/A')}")
        print(f"  Train: {config.get('train', 'N/A')}")
        print(f"  Val: {config.get('val', 'N/A')}")
        print(f"  Test: {config.get('test', 'N/A')}")

        # ê²½ë¡œ í™•ì¸
        if config.get('path') != str(self.dataset_dir):
            self.warnings.append(f"âš ï¸ data.yamlì˜ pathê°€ í˜„ì¬ ë””ë ‰í† ë¦¬ì™€ ë‹¤ë¦…ë‹ˆë‹¤")

        return config

    def validate_file_pairs(self, split):
        """ì´ë¯¸ì§€-ë¼ë²¨ íŒŒì¼ ìŒ ê²€ì¦"""
        images_dir = self.dataset_dir / split / 'images'
        labels_dir = self.dataset_dir / split / 'labels'

        if not images_dir.exists():
            self.errors.append(f"âŒ {split} ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì—†ìŒ: {images_dir}")
            return 0, 0, 0

        if not labels_dir.exists():
            self.errors.append(f"âŒ {split} ë¼ë²¨ ë””ë ‰í† ë¦¬ ì—†ìŒ: {labels_dir}")
            return 0, 0, 0

        # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡
        image_files = set()
        for ext in ['*.jpg', '*.png', '*.jpeg']:
            image_files.update([f.stem for f in images_dir.glob(ext)])

        # ë¼ë²¨ íŒŒì¼ ëª©ë¡
        label_files = set([f.stem for f in labels_dir.glob('*.txt')])

        # ë§¤ì¹­ í™•ì¸
        orphan_images = image_files - label_files
        orphan_labels = label_files - image_files
        matched = image_files & label_files

        if orphan_images:
            self.warnings.append(f"âš ï¸ {split}: ë¼ë²¨ì´ ì—†ëŠ” ì´ë¯¸ì§€ {len(orphan_images)}ê°œ")

        if orphan_labels:
            self.warnings.append(f"âš ï¸ {split}: ì´ë¯¸ì§€ê°€ ì—†ëŠ” ë¼ë²¨ {len(orphan_labels)}ê°œ")

        return len(matched), len(orphan_images), len(orphan_labels)

    def validate_labels(self, split, config):
        """ë¼ë²¨ íŒŒì¼ í˜•ì‹ ê²€ì¦"""
        labels_dir = self.dataset_dir / split / 'labels'

        if not labels_dir.exists():
            return {}

        class_counts = defaultdict(int)
        invalid_count = 0
        total_objects = 0
        empty_files = 0

        nc = config.get('nc', 22)

        for label_file in labels_dir.glob('*.txt'):
            with open(label_file, 'r') as f:
                lines = f.readlines()

            if not lines:
                empty_files += 1
                continue

            for line_num, line in enumerate(lines, 1):
                parts = line.strip().split()

                if len(parts) < 5:
                    invalid_count += 1
                    self.errors.append(f"âŒ {split}/{label_file.name}:{line_num} - í˜•ì‹ ì˜¤ë¥˜ (í•„ë“œ ë¶€ì¡±)")
                    continue

                try:
                    class_id = int(parts[0])
                    x, y, w, h = map(float, parts[1:5])

                    # í´ë˜ìŠ¤ ID ë²”ìœ„ í™•ì¸
                    if class_id < 0 or class_id >= nc:
                        invalid_count += 1
                        self.errors.append(f"âŒ {split}/{label_file.name}:{line_num} - ì˜ëª»ëœ í´ë˜ìŠ¤ ID: {class_id}")
                        continue

                    # ì¢Œí‘œ ë²”ìœ„ í™•ì¸ (0-1 ì •ê·œí™”)
                    if not (0 <= x <= 1 and 0 <= y <= 1 and 0 <= w <= 1 and 0 <= h <= 1):
                        invalid_count += 1
                        self.errors.append(f"âŒ {split}/{label_file.name}:{line_num} - ì˜ëª»ëœ ì¢Œí‘œ ë²”ìœ„")
                        continue

                    class_counts[class_id] += 1
                    total_objects += 1

                except ValueError as e:
                    invalid_count += 1
                    self.errors.append(f"âŒ {split}/{label_file.name}:{line_num} - ë³€í™˜ ì˜¤ë¥˜: {e}")

        return {
            'class_counts': class_counts,
            'total_objects': total_objects,
            'invalid_count': invalid_count,
            'empty_files': empty_files,
        }

    def print_class_distribution(self, split, stats, config):
        """í´ë˜ìŠ¤ë³„ ë¶„í¬ ì¶œë ¥"""
        class_counts = stats.get('class_counts', {})

        if not class_counts:
            return

        names = config.get('names', [])
        sorted_classes = sorted(class_counts.items(), key=lambda x: x[1], reverse=True)

        print(f"\n  í´ë˜ìŠ¤ë³„ ë¶„í¬:")
        for class_id, count in sorted_classes:
            class_name = names[class_id] if class_id < len(names) else f"Unknown_{class_id}"
            print(f"    {class_id:2d}. {class_name:22s}: {count:6,}ê°œ")

        # ë¶ˆê· í˜• ë¹„ìœ¨
        if len(class_counts) > 1:
            max_count = max(class_counts.values())
            min_count = min(class_counts.values())
            print(f"\n  ë¶ˆê· í˜• ë¹„ìœ¨: {max_count/min_count:.1f}:1")
            print(f"    ìµœëŒ€ ìƒ˜í”Œ: {max_count:,}ê°œ")
            print(f"    ìµœì†Œ ìƒ˜í”Œ: {min_count:,}ê°œ")
            print(f"    í‰ê·  ìƒ˜í”Œ: {sum(class_counts.values())/len(class_counts):,.0f}ê°œ")

    def check_training_readiness(self, all_stats):
        """í•™ìŠµ ì¤€ë¹„ ìƒíƒœ ì ê²€"""
        print("\n" + "="*80)
        print("5. í•™ìŠµ ì¤€ë¹„ ìƒíƒœ ì ê²€")
        print("="*80)

        ready = True

        # ìµœì†Œ ìƒ˜í”Œ ìˆ˜ í™•ì¸ (ê° splitë³„)
        for split in ['train', 'val', 'test']:
            stats = all_stats.get(split, {})
            class_counts = stats.get('class_counts', {})

            if not class_counts:
                ready = False
                self.errors.append(f"âŒ {split} setì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                continue

            min_samples = min(class_counts.values())
            if min_samples < 10:
                self.warnings.append(f"âš ï¸ {split} setì— ìƒ˜í”Œì´ 10ê°œ ë¯¸ë§Œì¸ í´ë˜ìŠ¤ê°€ ìˆìŠµë‹ˆë‹¤ (ìµœì†Œ: {min_samples}ê°œ)")

        # Train set í¬ê¸° í™•ì¸
        train_stats = all_stats.get('train', {})
        train_total = train_stats.get('total_objects', 0)
        if train_total < 1000:
            self.warnings.append(f"âš ï¸ Train set ê°ì²´ ìˆ˜ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤: {train_total}ê°œ")

        # Val set í¬ê¸° í™•ì¸
        val_stats = all_stats.get('val', {})
        val_total = val_stats.get('total_objects', 0)
        if val_total < 100:
            self.warnings.append(f"âš ï¸ Validation set ê°ì²´ ìˆ˜ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤: {val_total}ê°œ")

        if self.errors:
            print(f"\nâŒ ì‹¬ê°í•œ ì˜¤ë¥˜ {len(self.errors)}ê°œ:")
            for error in self.errors[:10]:  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
                print(f"  {error}")
            if len(self.errors) > 10:
                print(f"  ... ì™¸ {len(self.errors) - 10}ê°œ")
            ready = False

        if self.warnings:
            print(f"\nâš ï¸ ê²½ê³  {len(self.warnings)}ê°œ:")
            for warning in self.warnings[:10]:
                print(f"  {warning}")
            if len(self.warnings) > 10:
                print(f"  ... ì™¸ {len(self.warnings) - 10}ê°œ")

        if ready and not self.errors:
            print("\nâœ… í•™ìŠµ ì¤€ë¹„ ì™„ë£Œ!")
            print(f"  ì´ ì˜¤ë¥˜: 0ê°œ")
            print(f"  ì´ ê²½ê³ : {len(self.warnings)}ê°œ")
        else:
            print("\nâŒ í•™ìŠµ ì¤€ë¹„ ë¯¸ì™„ë£Œ - ì˜¤ë¥˜ ìˆ˜ì • í•„ìš”")

        return ready

    def run(self):
        """ì „ì²´ ê²€ì¦ ì‹¤í–‰"""
        print("\n" + "="*80)
        print("ìµœì¢… ë°ì´í„°ì…‹ ê²€ì¦ ì‹œì‘")
        print("="*80)
        print(f"ë°ì´í„°ì…‹ ê²½ë¡œ: {self.dataset_dir}\n")

        # 1. data.yaml ê²€ì¦
        config = self.load_config()
        if config is None:
            print("\nâŒ data.yamlì„ ë¡œë“œí•  ìˆ˜ ì—†ì–´ ê²€ì¦ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return False

        all_stats = {}

        # 2-4. ê° split ê²€ì¦
        for split in ['train', 'val', 'test']:
            print("\n" + "="*80)
            print(f"{split.upper()} SET ê²€ì¦")
            print("="*80)

            # íŒŒì¼ ìŒ ê²€ì¦
            matched, orphan_images, orphan_labels = self.validate_file_pairs(split)
            print(f"\n  íŒŒì¼ ë§¤ì¹­:")
            print(f"    âœ… ì •ìƒ ìŒ: {matched:,}ê°œ")
            if orphan_images > 0:
                print(f"    âš ï¸ ë¼ë²¨ ì—†ëŠ” ì´ë¯¸ì§€: {orphan_images}ê°œ")
            if orphan_labels > 0:
                print(f"    âš ï¸ ì´ë¯¸ì§€ ì—†ëŠ” ë¼ë²¨: {orphan_labels}ê°œ")

            # ë¼ë²¨ í˜•ì‹ ê²€ì¦
            stats = self.validate_labels(split, config)
            all_stats[split] = stats

            if stats:
                print(f"\n  ë¼ë²¨ í†µê³„:")
                print(f"    ì´ ê°ì²´: {stats['total_objects']:,}ê°œ")
                print(f"    ë¹ˆ ë¼ë²¨ íŒŒì¼: {stats['empty_files']}ê°œ")
                if stats['invalid_count'] > 0:
                    print(f"    âŒ ì˜¤ë¥˜ ë¼ë²¨: {stats['invalid_count']}ê°œ")

                # í´ë˜ìŠ¤ ë¶„í¬
                self.print_class_distribution(split, stats, config)

        # 5. í•™ìŠµ ì¤€ë¹„ ìƒíƒœ
        ready = self.check_training_readiness(all_stats)

        print("\n" + "="*80)
        print("ê²€ì¦ ì™„ë£Œ")
        print("="*80)

        return ready

if __name__ == "__main__":
    validator = DatasetValidator()
    ready = validator.run()

    if ready:
        print("\nğŸ‰ ë°ì´í„°ì…‹ì´ í•™ìŠµ ì¤€ë¹„ ì™„ë£Œ ìƒíƒœì…ë‹ˆë‹¤!")
        print(f"\në‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ í•™ìŠµì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
        print(f"  cd /home/sys1041/work_project")
        print(f"  yolo detect train data=data/processed/final_balanced_pcb_model/data.yaml \\")
        print(f"    model=yolov8l.pt epochs=150 imgsz=640 batch=32 device=0")
    else:
        print("\nâš ï¸ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•œ í›„ ë‹¤ì‹œ ê²€ì¦í•´ì£¼ì„¸ìš”.")
