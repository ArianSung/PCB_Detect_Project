"""
PCB ë¶ˆëŸ‰ ê²€ì‚¬ Flask ì¶”ë¡  ì„œë²„

ì‹¤í–‰ ë°©ë²•:
    python server/app.py

ë˜ëŠ”:
    flask --app server/app run --host=0.0.0.0 --port=5000
"""

# eventlet monkey patching ì œê±° (YOLO + OpenCVì™€ ì¶©ëŒ) âš ï¸
# threading ëª¨ë“œë¡œ ë³€ê²½í•˜ì—¬ ì•ˆì •ì„± í™•ë³´
# import eventlet
# eventlet.monkey_patch()

from flask import Flask, request, jsonify, Response, render_template_string
from flask_cors import CORS
from flask_socketio import SocketIO, emit  # WebSocket ì§€ì›
import base64
import cv2
import numpy as np
from datetime import datetime
import logging
import time
import os
from pathlib import Path
import threading
from collections import deque

# .env íŒŒì¼ ë¡œë“œ
try:
    from dotenv import load_dotenv
    # server/.env íŒŒì¼ ê²½ë¡œ
    env_path = Path(__file__).parent / '.env'
    load_dotenv(dotenv_path=env_path)
    print(f"âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ: {env_path}")
except ImportError:
    print("âš ï¸  python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    print("ğŸ’¡ ì„¤ì¹˜ ëª…ë ¹ì–´: pip install python-dotenv")

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from db_manager import DatabaseManager
from pcb_alignment import PCBAligner
from component_verification import ComponentVerifier
from template_based_alignment import TemplateBasedAlignment
from serial_number_detector import SerialNumberDetector
import json

# Flask ì•± ì´ˆê¸°í™”
app = Flask(__name__)
CORS(app)  # C# WinForms ì—°ë™ì„ ìœ„í•œ CORS í™œì„±í™”

# SocketIO ì´ˆê¸°í™” (WebSocket ì‹¤ì‹œê°„ í”„ë ˆì„ ìŠ¤íŠ¸ë¦¬ë°)
socketio = SocketIO(
    app,
    cors_allowed_origins="*",  # ëª¨ë“  Origin í—ˆìš© (í”„ë¡œë•ì…˜ì—ì„œëŠ” ì œí•œ í•„ìš”)
    async_mode='threading',     # threading ëª¨ë“œ (YOLO/OpenCV ì•ˆì •ì„± ìš°ì„ ) â­â­â­
    logger=True,                # ë””ë²„ê¹…ìš© ë¡œê·¸
    engineio_logger=True,       # Engine.IO ë””ë²„ê¹… ë¡œê·¸
    # ì†Œì¼“ íƒ€ì„ì•„ì›ƒ ì„¤ì • (ì¢€ë¹„ ì—°ê²° ë°©ì§€) â­
    ping_timeout=60,            # 60ì´ˆ ë™ì•ˆ ì‘ë‹µ ì—†ìœ¼ë©´ ì—°ê²° ì¢…ë£Œ
    ping_interval=25,           # 25ì´ˆë§ˆë‹¤ ping ì „ì†¡
    # ì—°ê²° ì„¤ì •
    max_http_buffer_size=10 * 1024 * 1024,  # 10MB (í”„ë ˆì„ í¬ê¸° ê³ ë ¤)
    async_handlers=True         # ë¹„ë™ê¸° í•¸ë“¤ëŸ¬ ì‚¬ìš© (ì„±ëŠ¥ í–¥ìƒ)
)
logger_socketio = logging.getLogger('socketio')
logger_socketio.setLevel(logging.INFO)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] [%(levelname)s] [Flask-Server] [%(module)s] - %(message)s'
)
logger = logging.getLogger(__name__)

# ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì € ì´ˆê¸°í™”
# í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” ì„¤ì • íŒŒì¼ì—ì„œ ì½ê¸° (ë‚˜ì¤‘ì— config.yamlë¡œ ì´ë™)
DB_CONFIG = {
    'host': os.getenv('DB_HOST', 'localhost'),
    'port': int(os.getenv('DB_PORT', 3306)),
    'user': os.getenv('DB_USER', 'root'),
    'password': os.getenv('DB_PASSWORD', 'your_password'),
    'database': os.getenv('DB_NAME', 'pcb_inspection')
}

db = DatabaseManager(**DB_CONFIG)

# YOLO ëª¨ë¸ ë¡œë“œ
try:
    from ultralytics import YOLO
    model_path = '../runs/detect/pcb_defect_v4_10class/weights/best.pt'  # 10 í´ë˜ìŠ¤ ëª¨ë¸ (mAP50=88.8%)
    yolo_model = YOLO(model_path)
    logger.info(f"âœ… YOLO ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
    logger.info(f"   - ëª¨ë¸ íƒ€ì…: YOLOv11l")
    logger.info(f"   - í´ë˜ìŠ¤ ìˆ˜: 10ê°œ (PCB ë¶€í’ˆ ê²€ì¶œ)")
except Exception as e:
    logger.error(f"âš ï¸  YOLO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    logger.warning("   - ì¶”ë¡  ì‹œ ë”ë¯¸ ê²°ê³¼ ë°˜í™˜ë¨")
    yolo_model = None

# í…œí”Œë¦¿ ê¸°ë°˜ ì •ë ¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
template_alignment = None
try:
    template_path = Path(__file__).parent / 'reference_hole.jpg'
    if template_path.exists():
        template_alignment = TemplateBasedAlignment(str(template_path), threshold=0.90)  # ì‹ ë¢°ë„ ì„ê³„ê°’ 0.90 (90%) â­
        logger.info(f"âœ… í…œí”Œë¦¿ ê¸°ë°˜ ì •ë ¬ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ")
        logger.info(f"   - í…œí”Œë¦¿ ê²½ë¡œ: {template_path}")
        logger.info(f"   - í…œí”Œë¦¿ í¬ê¸°: {template_alignment.template.shape if template_alignment.template is not None else 'N/A'}")
        logger.info(f"   - ì‹ ë¢°ë„ ì„ê³„ê°’: {template_alignment.threshold:.2f} (90%)")
    else:
        logger.warning(f"âš ï¸  í…œí”Œë¦¿ íŒŒì¼ ì—†ìŒ: {template_path}")
        logger.warning("   - í…œí”Œë¦¿ ë§¤ì¹­ ê¸°ëŠ¥ ë¹„í™œì„±í™”")
except Exception as e:
    logger.error(f"âš ï¸  í…œí”Œë¦¿ ê¸°ë°˜ ì •ë ¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    template_alignment = None

# ì‹œë¦¬ì–¼ ë„˜ë²„ OCR ê²€ì¶œê¸° ì´ˆê¸°í™”
serial_detector = None
try:
    serial_detector = SerialNumberDetector(
        languages=['en'],  # ì˜ì–´ OCR
        gpu=True,  # GPU ì‚¬ìš©
        min_confidence=0.3  # ìµœì†Œ ì‹ ë¢°ë„ 30%
    )
    logger.info("âœ… ì‹œë¦¬ì–¼ ë„˜ë²„ OCR ê²€ì¶œê¸° ì´ˆê¸°í™” ì™„ë£Œ")
except Exception as e:
    logger.error(f"âš ï¸  ì‹œë¦¬ì–¼ ë„˜ë²„ OCR ê²€ì¶œê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    serial_detector = None

# PCB ì •ë ¬ ë° ì»´í¬ë„ŒíŠ¸ ê²€ì¦ ëª¨ë“ˆ ì´ˆê¸°í™”
pcb_aligner_left = None
pcb_aligner_right = None
component_verifier_left = None
component_verifier_right = None

try:
    # ê¸°ì¤€ ë°ì´í„° ë¡œë“œ (ì¢Œì¸¡)
    left_ref_path = Path(__file__).parent / 'reference_data' / 'reference_left.json'
    if left_ref_path.exists():
        with open(left_ref_path, 'r', encoding='utf-8') as f:
            left_reference_data = json.load(f)

        # PCBAligner ì´ˆê¸°í™” (ì¢Œì¸¡)
        pcb_aligner_left = PCBAligner(left_reference_data)

        # ComponentVerifier ì´ˆê¸°í™” (ì¢Œì¸¡)
        component_verifier_left = ComponentVerifier(
            reference_components=left_reference_data['components'],
            position_threshold=20.0,  # 20í”½ì…€ ì´ë‚´
            confidence_threshold=0.25
        )

        logger.info(f"âœ… ì¢Œì¸¡ PCB ê¸°ì¤€ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {left_ref_path}")
        logger.info(f"   - ë‚˜ì‚¬ êµ¬ë©: {len(left_reference_data['mounting_holes'])}ê°œ")
        logger.info(f"   - ê¸°ì¤€ ì»´í¬ë„ŒíŠ¸: {len(left_reference_data['components'])}ê°œ")
    else:
        logger.warning(f"âš ï¸  ì¢Œì¸¡ ê¸°ì¤€ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {left_ref_path}")
        logger.warning("   - PCB ì •ë ¬ ë° ì»´í¬ë„ŒíŠ¸ ê²€ì¦ ë¹„í™œì„±í™” (ì¢Œì¸¡)")
except Exception as e:
    logger.error(f"âš ï¸  ì¢Œì¸¡ ê¸°ì¤€ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    logger.warning("   - PCB ì •ë ¬ ë° ì»´í¬ë„ŒíŠ¸ ê²€ì¦ ë¹„í™œì„±í™” (ì¢Œì¸¡)")

try:
    # ê¸°ì¤€ ë°ì´í„° ë¡œë“œ (ìš°ì¸¡)
    right_ref_path = Path(__file__).parent / 'reference_data' / 'reference_right.json'
    if right_ref_path.exists():
        with open(right_ref_path, 'r', encoding='utf-8') as f:
            right_reference_data = json.load(f)

        # PCBAligner ì´ˆê¸°í™” (ìš°ì¸¡)
        pcb_aligner_right = PCBAligner(right_reference_data)

        # ComponentVerifier ì´ˆê¸°í™” (ìš°ì¸¡)
        component_verifier_right = ComponentVerifier(
            reference_components=right_reference_data['components'],
            position_threshold=20.0,  # 20í”½ì…€ ì´ë‚´
            confidence_threshold=0.25
        )

        logger.info(f"âœ… ìš°ì¸¡ PCB ê¸°ì¤€ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {right_ref_path}")
        logger.info(f"   - ë‚˜ì‚¬ êµ¬ë©: {len(right_reference_data['mounting_holes'])}ê°œ")
        logger.info(f"   - ê¸°ì¤€ ì»´í¬ë„ŒíŠ¸: {len(right_reference_data['components'])}ê°œ")
    else:
        logger.warning(f"âš ï¸  ìš°ì¸¡ ê¸°ì¤€ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {right_ref_path}")
        logger.warning("   - PCB ì •ë ¬ ë° ì»´í¬ë„ŒíŠ¸ ê²€ì¦ ë¹„í™œì„±í™” (ìš°ì¸¡)")
except Exception as e:
    logger.error(f"âš ï¸  ìš°ì¸¡ ê¸°ì¤€ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    logger.warning("   - PCB ì •ë ¬ ë° ì»´í¬ë„ŒíŠ¸ ê²€ì¦ ë¹„í™œì„±í™” (ìš°ì¸¡)")

# ì‹¤ì‹œê°„ ë·°ì–´ë¥¼ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
latest_frames = {
    'left': None,
    'right': None
}
# JPEG ìºì‹± (WebSocket ì„±ëŠ¥ ìµœì í™”) â­
latest_frames_jpeg = {
    'left': None,  # Base64 encoded JPEG ë¬¸ìì—´
    'right': None
}
latest_results = {
    'left': {},
    'right': {}
}
frame_lock = threading.Lock()

# Temporal Smoothing ì„¤ì • (ê¹œë¹¡ê±°ë¦¼ ìµœì†Œí™”)
HISTORY_SIZE = 15         # ìµœê·¼ 15í”„ë ˆì„ ì €ì¥
MIN_DETECTION_FRAMES = 5  # ìµœì†Œ 5í”„ë ˆì„ ê²€ì¶œ ì‹œ í‘œì‹œ (ë§¤ìš° ì•ˆì •ì ) â­
MAX_MISSING_FRAMES = 20   # ì‚¬ë¼ì§„ í›„ 20í”„ë ˆì„ê¹Œì§€ ìœ ì§€ (ë§¤ìš° ì˜¤ë˜ ìœ ì§€) â­
IOU_THRESHOLD = 0.05      # 5% ì´ìƒë§Œ ê²¹ì³ë„ ê°™ì€ ê°ì²´ë¡œ íŒë‹¨ (ê·¹ë„ë¡œ ê´€ëŒ€) â­â­
CONFIDENCE_THRESHOLD = 0.3  # ì‹ ë¢°ë„ 30% ì´ìƒë§Œ ì‚¬ìš©
FREEZE_AFTER_FRAMES = 9999  # í”„ë¡œì¦Œ ê¸°ëŠ¥ ë¹„í™œì„±í™” (ì‚¬ìš©ì ìš”ì²­) â­â­â­

# ROI ì„¤ì • (PCB ìë™ ê°ì§€ ë° ë‚´ë¶€ ì˜ì—­ë§Œ ê²€ì¶œ) â­â­â­
PCB_COLOR_LOWER_HSV = np.array([35, 40, 40])    # ì´ˆë¡ìƒ‰ í•˜í•œ (HSV)
PCB_COLOR_UPPER_HSV = np.array([85, 255, 255])  # ì´ˆë¡ìƒ‰ ìƒí•œ (HSV)
PCB_INNER_MARGIN_PERCENT = 0.03  # PCB í…Œë‘ë¦¬ 3% ì œì™¸ (íŒŒë€ìƒ‰ ì„ ì— ê°€ê¹ê²Œ) â­
PCB_EDGE_THRESHOLD = 10  # PCBê°€ í”„ë ˆì„ ê²½ê³„ì—ì„œ ìµœì†Œ 10í”½ì…€ ë–¨ì–´ì ¸ì•¼ ì „ì²´ë¡œ ê°„ì£¼

# ëª¨ì…˜ ê°ì§€ ì„¤ì • (ìƒˆ PCB ì§„ì… ê°ì§€) â­â­â­
MOTION_THRESHOLD = 30.0    # í”„ë ˆì„ ì°¨ì´ ì„ê³„ê°’ (í”½ì…€ í‰ê·  ì°¨ì´)
STABLE_FRAMES_FOR_FREEZE = 10  # 10í”„ë ˆì„ ë™ì•ˆ ì•ˆì • ì‹œ frozen ëª¨ë“œ

# ê²€ì¶œ íˆìŠ¤í† ë¦¬ (ì¹´ë©”ë¼ë³„)
detection_history = {
    'left': deque(maxlen=HISTORY_SIZE),
    'right': deque(maxlen=HISTORY_SIZE)
}

# ì¶”ì  ì¤‘ì¸ ê°ì²´ (ì¹´ë©”ë¼ë³„)
tracked_objects = {
    'left': {},   # {object_id: {'box': {...}, 'class_id': int, 'class_name': str, 'confidence': float, 'count': int, 'missing': int}}
    'right': {}
}
next_object_id = 0
tracking_lock = threading.Lock()

# ì™„ì „ ì •ì§€ ëª¨ë“œ (ëª¨ë“  ê°ì²´ê°€ frozen ìƒíƒœê°€ ë˜ë©´ í”„ë ˆì„ ì—…ë°ì´íŠ¸ ì¤‘ì§€) â­â­â­
camera_frozen_state = {
    'left': False,   # Trueê°€ ë˜ë©´ í”„ë ˆì„ ì—…ë°ì´íŠ¸ ì¤‘ì§€
    'right': False
}

# ëª¨ì…˜ ê°ì§€ìš© ì´ì „ í”„ë ˆì„ ì €ì¥ (ìƒˆ PCB ì§„ì… ê°ì§€) â­â­â­
previous_frames = {
    'left': None,
    'right': None
}

# ì•ˆì • í”„ë ˆì„ ì¹´ìš´í„° (ì›€ì§ì„ ì—†ëŠ” í”„ë ˆì„ ìˆ˜) â­â­â­
stable_frame_count = {
    'left': 0,
    'right': 0
}


@app.route('/health', methods=['GET'])
def health_check():
    """ì„œë²„ ìƒíƒœ ì²´í¬"""
    return jsonify({
        'status': 'ok',
        'timestamp': datetime.now().isoformat(),
        'server': 'Flask PCB Inspection Server',
        'version': '1.0.0'
    })


@app.route('/save_reference_components', methods=['POST'])
def save_reference_components():
    """
    ê¸°ì¤€ ë¶€í’ˆ ë°°ì¹˜ ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥

    Request JSON:
        {
            "product_code": "BC",
            "components": [
                {
                    "class_name": "resistor",
                    "center": [100, 200],
                    "relative_center": [10, 20],  # í…œí”Œë¦¿ ê¸°ì¤€ì  ê¸°ì¤€
                    "bbox": [95, 195, 105, 205],
                    "confidence": 0.95
                },
                ...
            ],
            "reference_point": [90, 180],  # í…œí”Œë¦¿ ê¸°ì¤€ì  ìœ„ì¹˜
            "tolerance_px": 30.0  # ì¹´ë©”ë¼ ê±°ë¦¬ ì°¨ì´ ê³ ë ¤í•œ í—ˆìš© ì˜¤ì°¨
        }

    Response JSON:
        {
            "status": "ok",
            "product_code": "BC",
            "components_saved": 22,
            "message": "ê¸°ì¤€ ë¶€í’ˆ ë°°ì¹˜ ì •ë³´ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤"
        }
    """
    try:
        data = request.get_json()

        product_code = data.get('product_code', 'BC')
        components = data.get('components', [])
        tolerance_px = data.get('tolerance_px', 30.0)  # ì¹´ë©”ë¼ ê±°ë¦¬ ì°¨ì´ ê³ ë ¤

        if not components:
            return jsonify({
                'status': 'error',
                'error': 'No components provided'
            }), 400

        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° ì»¤ì„œ ê°€ì ¸ì˜¤ê¸°
        conn = db.get_connection()
        with conn.cursor() as cursor:
            # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ì—…ë°ì´íŠ¸ ëª¨ë“œ)
            delete_query = "DELETE FROM product_components WHERE product_code = %s"
            cursor.execute(delete_query, (product_code,))

            # ìƒˆë¡œìš´ ê¸°ì¤€ ë°ì´í„° ì €ì¥
            insert_query = """
                INSERT INTO product_components
                (product_code, component_class, center_x, center_y,
                 bbox_x1, bbox_y1, bbox_x2, bbox_y2, tolerance_px)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
            """

            saved_count = 0
            for comp in components:
                # ìƒëŒ€ ì¢Œí‘œë¥¼ ì‚¬ìš© (í…œí”Œë¦¿ ê¸°ì¤€ì  ê¸°ì¤€)
                if 'relative_center' in comp:
                    center_x, center_y = comp['relative_center']
                else:
                    center_x, center_y = comp['center']

                bbox = comp['bbox']

                params = (
                    product_code,
                    comp['class_name'],
                    float(center_x),
                    float(center_y),
                    float(bbox[0]),
                    float(bbox[1]),
                    float(bbox[2]),
                    float(bbox[3]),
                    float(tolerance_px)
                )

                cursor.execute(insert_query, params)
                saved_count += 1

            # products í…Œì´ë¸”ì˜ component_count ì—…ë°ì´íŠ¸
            update_product_query = """
                UPDATE products
                SET component_count = %s
                WHERE product_code = %s
            """
            cursor.execute(update_product_query, (saved_count, product_code))

        logger.info(f"âœ… ê¸°ì¤€ ë¶€í’ˆ ë°°ì¹˜ ì €ì¥ ì™„ë£Œ: {product_code} ({saved_count}ê°œ ë¶€í’ˆ)")

        return jsonify({
            'status': 'ok',
            'product_code': product_code,
            'components_saved': saved_count,
            'tolerance_px': tolerance_px,
            'message': f'ê¸°ì¤€ ë¶€í’ˆ ë°°ì¹˜ ì •ë³´ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤ ({saved_count}ê°œ ë¶€í’ˆ)'
        })

    except Exception as e:
        logger.error(f"ê¸°ì¤€ ë¶€í’ˆ ë°°ì¹˜ ì €ì¥ ì‹¤íŒ¨: {e}", exc_info=True)
        return jsonify({
            'status': 'error',
            'error': str(e)
        }), 500


@app.route('/predict_serial', methods=['POST'])
def predict_serial():
    """
    ì‹œë¦¬ì–¼ ë„˜ë²„ OCR ê²€ì¶œ API (ë’·ë©´ ì¹´ë©”ë¼ìš©)

    Request JSON:
        {
            "camera_id": "right",  # ë’·ë©´ ì¹´ë©”ë¼
            "frame": "<base64_encoded_image>",  # Base64 ì¸ì½”ë”©ëœ JPEG ì´ë¯¸ì§€
            "timestamp": "2025-12-03T14:35:22.123Z"  # ISO í¬ë§· íƒ€ì„ìŠ¤íƒ¬í”„
        }

    Response JSON:
        {
            "status": "ok" or "error",
            "serial_number": "MBBC-00000001",  # ì „ì²´ ì‹œë¦¬ì–¼ ë„˜ë²„
            "product_code": "BC",  # ì œí’ˆ ì½”ë“œ (2ìë¦¬)
            "sequence_number": "00000001",  # ì¼ë ¨ë²ˆí˜¸ (8ìë¦¬)
            "confidence": 0.95,  # OCR ì‹ ë¢°ë„ (0.0~1.0)
            "detected_text": "S/N MBBC-00000001",  # ì›ë³¸ ê²€ì¶œ í…ìŠ¤íŠ¸
            "inference_time_ms": 123.45,  # OCR ì²˜ë¦¬ ì‹œê°„ (ms)
            "error": "ì—ëŸ¬ ë©”ì‹œì§€ (ì‹¤íŒ¨ ì‹œ)"
        }
    """
    try:
        start_time = time.time()

        # ìš”ì²­ ë°ì´í„° íŒŒì‹±
        data = request.get_json()
        camera_id = data.get('camera_id', 'right')
        frame_base64 = data.get('frame')
        timestamp = data.get('timestamp', datetime.now().isoformat())

        if not frame_base64:
            return jsonify({
                'status': 'error',
                'error': 'í”„ë ˆì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'
            }), 400

        # Base64 ë””ì½”ë”©
        try:
            image_data = base64.b64decode(frame_base64)
            np_arr = np.frombuffer(image_data, np.uint8)
            frame = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)

            if frame is None:
                raise ValueError("ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨")

        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨: {e}")
            return jsonify({
                'status': 'error',
                'error': f'ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨: {str(e)}'
            }), 400

        # ì‹œë¦¬ì–¼ ë„˜ë²„ ê²€ì¶œê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ì„ ê²½ìš°
        if serial_detector is None:
            logger.error("ì‹œë¦¬ì–¼ ë„˜ë²„ ê²€ì¶œê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return jsonify({
                'status': 'error',
                'error': 'ì‹œë¦¬ì–¼ ë„˜ë²„ ê²€ì¶œê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤',
                'serial_number': None,
                'product_code': None,
                'confidence': 0.0
            }), 500

        # ì‹œë¦¬ì–¼ ë„˜ë²„ ê²€ì¶œ
        ocr_result = serial_detector.detect_serial_number(frame)

        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        inference_time_ms = (time.time() - start_time) * 1000

        # ì‘ë‹µ êµ¬ì„±
        response = {
            'status': ocr_result['status'],
            'serial_number': ocr_result.get('serial_number'),
            'product_code': ocr_result.get('product_code'),
            'sequence_number': ocr_result.get('sequence_number'),
            'confidence': ocr_result.get('confidence', 0.0),
            'detected_text': ocr_result.get('detected_text', ''),
            'inference_time_ms': inference_time_ms,
            'timestamp': timestamp,
            'camera_id': camera_id
        }

        # ì—ëŸ¬ê°€ ìˆì„ ê²½ìš° ì¶”ê°€
        if 'error' in ocr_result:
            response['error'] = ocr_result['error']

        # ì„±ê³µ ì‹œ ë¡œê·¸
        if ocr_result['status'] == 'ok':
            logger.info(
                f"âœ… [{camera_id}] ì‹œë¦¬ì–¼ ë„˜ë²„ ê²€ì¶œ ì„±ê³µ: {ocr_result['serial_number']} "
                f"(ì œí’ˆ: {ocr_result['product_code']}, ì‹ ë¢°ë„: {ocr_result['confidence']:.2%}, "
                f"ì²˜ë¦¬ ì‹œê°„: {inference_time_ms:.1f}ms)"
            )
        else:
            logger.warning(
                f"âš ï¸  [{camera_id}] ì‹œë¦¬ì–¼ ë„˜ë²„ ê²€ì¶œ ì‹¤íŒ¨: {ocr_result.get('error', 'Unknown')}"
            )

        return jsonify(response), 200

    except Exception as e:
        logger.error(f"âŒ /predict_serial ì²˜ë¦¬ ì‹¤íŒ¨: {e}", exc_info=True)
        return jsonify({
            'status': 'error',
            'error': str(e),
            'serial_number': None,
            'product_code': None,
            'confidence': 0.0
        }), 500


@app.route('/predict_test', methods=['POST'])
def predict_test():
    """
    ì¹´ë©”ë¼ í…ŒìŠ¤íŠ¸ìš© ì—”ë“œí¬ì¸íŠ¸ (DB ì €ì¥ ì—†ìŒ)

    Request JSON:
        {
            "camera_id": "left" or "right",
            "image": "base64_encoded_jpeg_image"
        }

    Response JSON:
        {
            "status": "ok",
            "camera_id": "left",
            "defect_type": "ì •ìƒ",
            "confidence": 0.95,
            "inference_time_ms": 5.2,
            "timestamp": "2025-01-27T15:30:45.123456",
            "note": "í…ŒìŠ¤íŠ¸ ëª¨ë“œ (DB ì €ì¥ ì•ˆ í•¨)"
        }
    """
    start_time = time.time()

    try:
        # 1. ìš”ì²­ ë°ì´í„° ê²€ì¦
        data = request.get_json()
        if not data:
            return jsonify({
                'status': 'error',
                'error': 'Request body is empty'
            }), 400

        camera_id = data.get('camera_id')
        image_base64 = data.get('image')

        if not camera_id or not image_base64:
            return jsonify({
                'status': 'error',
                'error': 'Missing required fields: camera_id, image'
            }), 400

        # 2. Base64 ë””ì½”ë”© ë° í”„ë ˆì„ ê²€ì¦
        try:
            image_bytes = base64.b64decode(image_base64)
            nparr = np.frombuffer(image_bytes, np.uint8)
            frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

            if frame is None or frame.size == 0:
                return jsonify({
                    'status': 'error',
                    'error': 'Invalid image data: failed to decode'
                }), 400

            logger.info(f"[TEST] í”„ë ˆì„ ìˆ˜ì‹  ì„±ê³µ: {camera_id} (ì›ë³¸ shape: {frame.shape})")

            # ì¤‘ì•™ í¬ë¡­ (640x480 â†’ 640x640) â­â­â­
            frame = crop_to_square(frame, target_size=640)
            logger.info(f"[TEST] ì¤‘ì•™ í¬ë¡­ ì™„ë£Œ: {camera_id} (í¬ë¡­ í›„ shape: {frame.shape})")

        except Exception as decode_error:
            return jsonify({
                'status': 'error',
                'error': f'Failed to decode image: {str(decode_error)}'
            }), 400

        # 2-1. ëª¨ì…˜ ê°ì§€ (ìƒˆ PCB ì§„ì… í™•ì¸) â­â­â­
        motion_detected, motion_value = detect_motion(frame, previous_frames.get(camera_id), camera_id)

        if motion_detected:
            # í° ì›€ì§ì„ ê°ì§€ â†’ ìƒˆ PCB ì§„ì…!
            logger.info(f"ğŸš¨ [{camera_id}] ëª¨ì…˜ ê°ì§€! (ì°¨ì´: {motion_value:.1f}) â†’ ì¶”ë¡  ì¬ê°œ")

            # frozen ìƒíƒœ ë¦¬ì…‹
            with tracking_lock:
                camera_frozen_state[camera_id] = False
                stable_frame_count[camera_id] = 0
                tracked_objects[camera_id].clear()  # ëª¨ë“  ì¶”ì  ê°ì²´ ì´ˆê¸°í™”
                logger.info(f"ğŸ”“ [{camera_id}] frozen ìƒíƒœ ë¦¬ì…‹ ì™„ë£Œ")
        else:
            # ì›€ì§ì„ ì—†ìŒ â†’ ì•ˆì • í”„ë ˆì„ ì¦ê°€
            stable_frame_count[camera_id] += 1

        # ì´ì „ í”„ë ˆì„ ì—…ë°ì´íŠ¸
        previous_frames[camera_id] = frame.copy()

        # 2-2. ì™„ì „ ì •ì§€ ëª¨ë“œ í™•ì¸ (ëª¨ë“  ê°ì²´ê°€ frozen ìƒíƒœë©´ ì¶”ë¡  ê±´ë„ˆë›°ê¸°) â­â­â­
        if camera_frozen_state.get(camera_id, False):
            # ì´ë¯¸ frozen ìƒíƒœ - ì¶”ë¡ í•˜ì§€ ì•Šê³  ê¸°ì¡´ ê²°ê³¼ ë°˜í™˜
            with frame_lock:
                existing_result = latest_results.get(camera_id, {})

            if existing_result:
                logger.info(f"ğŸ”’ [{camera_id}] ì •ì§€ ëª¨ë“œ - ê¸°ì¡´ ê²°ê³¼ ë°˜í™˜ (ì¶”ë¡  ìƒëµ)")
                return jsonify(existing_result)
            else:
                # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ í•œ ë²ˆë§Œ ì¶”ë¡  ì‹¤í–‰ (ì´ˆê¸°í™”)
                logger.info(f"âš ï¸  [{camera_id}] ì •ì§€ ëª¨ë“œì§€ë§Œ ê¸°ì¡´ ê²°ê³¼ ì—†ìŒ - ì´ˆê¸° ì¶”ë¡  ì‹¤í–‰")

        # 3. PCB ROI ê°ì§€ (ë¹„í™œì„±í™” - ì•”ë§‰ ì¤€ë¹„ í›„ í™œì„±í™” ì˜ˆì •) â­â­â­
        # roi_mask, pcb_bbox, roi_bbox = detect_pcb_roi(frame)
        # if pcb_bbox is not None:
        #     logger.info(f"[TEST] PCB ê°ì§€ ì„±ê³µ: {camera_id} â†’ PCB {pcb_bbox}, ROI {roi_bbox}")
        # else:
        #     logger.warning(f"[TEST] PCB ê°ì§€ ì‹¤íŒ¨: {camera_id} â†’ ì „ì²´ í”„ë ˆì„ ì‚¬ìš©")

        # ROI ë¹„í™œì„±í™” - ì „ì²´ í”„ë ˆì„ ì‚¬ìš©
        pcb_bbox, roi_bbox = None, None

        # 3-1. í…œí”Œë¦¿ ë§¤ì¹­ + ROI ì²´í¬ â­â­â­
        should_run_yolo = False
        roi_status = "unknown"
        reference_point = None

        if template_alignment and template_alignment.template is not None:
            # YOLO ê²€ì¶œìš© ROI ì˜ì—­ ì •ì˜ (ì¢Œìš° í™•ì¥ + ìœ„ë¡œ 70í”½ì…€ ì´ë™)
            img_h, img_w = frame.shape[:2]
            yolo_width = 600  # 550 â†’ 600 (+50)
            yolo_height = 415
            yolo_roi_x1 = (img_w - yolo_width) // 2   # 20
            yolo_roi_y1 = (img_h - yolo_height) // 2 - 70  # 42 (112-70)
            yolo_roi_x2 = yolo_roi_x1 + yolo_width    # 620
            yolo_roi_y2 = yolo_roi_y1 + yolo_height   # 457

            # í…œí”Œë¦¿ ë§¤ì¹­ìš© ROI ì˜ì—­ ì •ì˜ (YOLO ROI ì™¼ìª½ ìƒë‹¨ ëª¨ì„œë¦¬ì— ì •ë ¬)
            roi_size = 60       # ROI í¬ê¸° (ì •ì‚¬ê°í˜•)
            # YOLO ROI ì™¼ìª½ ìƒë‹¨ ëª¨ì„œë¦¬ ì¢Œí‘œë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            roi_x1 = yolo_roi_x1                    # 20
            roi_y1 = yolo_roi_y1                    # 42
            roi_x2 = roi_x1 + roi_size              # 80
            roi_y2 = roi_y1 + roi_size              # 102

            # í…œí”Œë¦¿ ë§¤ì¹­
            reference_point = template_alignment.find_reference_point(
                frame,
                method=cv2.TM_CCORR_NORMED,
                roi=None
            )

            if reference_point:
                ref_x, ref_y = reference_point
                is_in_roi = (roi_x1 <= ref_x <= roi_x2 and roi_y1 <= ref_y <= roi_y2)

                if is_in_roi:
                    should_run_yolo = True
                    roi_status = "in_roi"
                    logger.info(f"[TEST] âœ… í…œí”Œë¦¿ì´ ROI ì•ˆ: {camera_id} ({ref_x}, {ref_y}) â†’ YOLO ì‹¤í–‰")
                else:
                    should_run_yolo = False
                    roi_status = "out_of_roi"
                    logger.warning(f"[TEST] âš ï¸ í…œí”Œë¦¿ì´ ROI ë°–: {camera_id} ({ref_x}, {ref_y}) â†’ YOLO ê±´ë„ˆë›°ê¸°")

                # ROI ìƒíƒœ broadcast
                socketio.emit('roi_status', {
                    'camera_id': camera_id,
                    'status': roi_status,
                    'reference_point': [int(ref_x), int(ref_y)],
                    'roi': [roi_x1, roi_y1, roi_x2, roi_y2]
                })

        # 3-2. í…œí”Œë¦¿ ë§¤ì¹­ ì‹¤íŒ¨ ì²˜ë¦¬
        if template_alignment and template_alignment.template is not None:
            if not reference_point:
                logger.warning(f"[TEST] í…œí”Œë¦¿ ë§¤ì¹­ ì‹¤íŒ¨: {camera_id}")
                should_run_yolo = False
                roi_status = "template_not_found"
        else:
            # í…œí”Œë¦¿ì´ ì—†ìœ¼ë©´ í•­ìƒ YOLO ì‹¤í–‰ (ê¸°ì¡´ ë™ì‘ ìœ ì§€)
            should_run_yolo = True
            roi_status = "no_template"
            logger.info(f"[TEST] í…œí”Œë¦¿ ì—†ìŒ â†’ í•­ìƒ YOLO ì‹¤í–‰: {camera_id}")

        # 4. AI ì¶”ë¡  (YOLO ëª¨ë¸, ROI ì¡°ê±´ë¶€ ì‹¤í–‰) â­â­â­
        boxes_data = []
        if yolo_model is not None and should_run_yolo:
            try:
                # YOLO ì¶”ë¡  ì‹¤í–‰ (ROI ì˜ì—­ë§Œ ì‚¬ìš©)
                # ì°¸ê³ : ROI ë§ˆìŠ¤í¬ë¥¼ ì§ì ‘ ì ìš©í•˜ì§€ ì•Šê³ , ì¶”ë¡  í›„ í•„í„°ë§ìœ¼ë¡œ ì²˜ë¦¬
                results = yolo_model(frame, verbose=False)
                defect_type, confidence, raw_boxes_data = parse_yolo_results(results)

                # ì‹ ë¢°ë„ í•„í„°ë§ (ë‚®ì€ ì‹ ë¢°ë„ ì œê±°)
                filtered_boxes = [box for box in raw_boxes_data if box['confidence'] >= CONFIDENCE_THRESHOLD]

                # YOLO ROI í•„í„°ë§ (í…œí”Œë¦¿ì´ ROI ì•ˆì— ìˆì„ ë•Œë§Œ) â­â­â­
                if template_alignment and template_alignment.template is not None and reference_point:
                    roi_filtered_boxes = []
                    for box in filtered_boxes:
                        # ë°”ìš´ë”© ë°•ìŠ¤ ì¤‘ì‹¬ì ì´ YOLO ROI ì•ˆì— ìˆëŠ”ì§€ í™•ì¸
                        cx = (box['x1'] + box['x2']) / 2
                        cy = (box['y1'] + box['y2']) / 2
                        if yolo_roi_x1 <= cx <= yolo_roi_x2 and yolo_roi_y1 <= cy <= yolo_roi_y2:
                            roi_filtered_boxes.append(box)
                    logger.info(f"[TEST] YOLO ROI í•„í„°ë§: {camera_id} â†’ {len(filtered_boxes)}ê°œ â†’ {len(roi_filtered_boxes)}ê°œ")
                    filtered_boxes = roi_filtered_boxes

                # ê²€ì¶œ ê²°ê³¼ í‰í™œí™” (Temporal Smoothing)
                smoothed_boxes = smooth_detections(camera_id, filtered_boxes)

                # í‰í™œí™”ëœ ê²°ê³¼ë¡œ ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (PCB, ROI ë°•ìŠ¤ë„ í•¨ê»˜ í‘œì‹œ)
                annotated_frame = draw_bounding_boxes(frame.copy(), smoothed_boxes, pcb_bbox, roi_bbox)

                logger.info(f"[TEST] YOLO ì¶”ë¡  ì™„ë£Œ: {camera_id} â†’ ì›ë³¸ {len(raw_boxes_data)}ê°œ â†’ í•„í„°ë§ {len(filtered_boxes)}ê°œ â†’ í‰í™œí™” {len(smoothed_boxes)}ê°œ ê°ì²´")

                # ë””ë²„ê·¸ ë·°ì–´ìš© ë°ì´í„° êµ¬ì¡° ë³€í™˜ (JavaScriptê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ) â­
                boxes_data = []
                for box in filtered_boxes:
                    cx = (box['x1'] + box['x2']) / 2
                    cy = (box['y1'] + box['y2']) / 2

                    box_data = {
                        'class_name': box['class_name'],
                        'bbox': [box['x1'], box['y1'], box['x2'], box['y2']],
                        'center': [cx, cy],
                        'confidence': box['confidence']
                    }

                    # í…œí”Œë¦¿ ê¸°ì¤€ì ì„ (0,0)ìœ¼ë¡œ í•˜ëŠ” ìƒëŒ€ ì¢Œí‘œ ì¶”ê°€ â­
                    if reference_point:
                        ref_x, ref_y = reference_point
                        rel_x = cx - ref_x
                        rel_y = cy - ref_y
                        box_data['relative_center'] = [rel_x, rel_y]

                    boxes_data.append(box_data)
            except Exception as yolo_error:
                logger.error(f"[TEST] YOLO ì¶”ë¡  ì‹¤íŒ¨: {yolo_error}")
                defect_type = "ì •ìƒ"
                confidence = 0.0
                annotated_frame = frame.copy()
        elif not should_run_yolo:
            # ROI ë°– ë˜ëŠ” í…œí”Œë¦¿ ë§¤ì¹­ ì‹¤íŒ¨ - YOLO ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
            logger.info(f"[TEST] YOLO ê±´ë„ˆë›°ê¸°: {camera_id} (ROI ìƒíƒœ: {roi_status})")
            defect_type = "ì •ìƒ"
            confidence = 0.0
            annotated_frame = frame.copy()
        else:
            logger.warning("[TEST] YOLO ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ - ë”ë¯¸ ê²°ê³¼ ë°˜í™˜")
            defect_type = "ì •ìƒ"
            confidence = 0.95
            annotated_frame = frame.copy()

        # 5. ROI + í…œí”Œë¦¿ ì‹œê°í™” ì˜¤ë²„ë ˆì´ (annotated_frame ìœ„ì— ê·¸ë¦¬ê¸°) â­â­â­
        if template_alignment and template_alignment.template is not None:
            img_h, img_w = annotated_frame.shape[:2]

            # YOLO ê²€ì¶œìš© ROI ì¬ê³„ì‚° (ì‹œê°í™”ìš©, ì¢Œìš° í™•ì¥ + ìœ„ë¡œ 70í”½ì…€ ì´ë™)
            yolo_width = 600  # 550 â†’ 600 (+50)
            yolo_height = 415
            yolo_roi_x1 = (img_w - yolo_width) // 2   # 20
            yolo_roi_y1 = (img_h - yolo_height) // 2 - 70  # 42 (112-70)
            yolo_roi_x2 = yolo_roi_x1 + yolo_width    # 620
            yolo_roi_y2 = yolo_roi_y1 + yolo_height   # 457

            # í…œí”Œë¦¿ ë§¤ì¹­ìš© ROI ì¬ê³„ì‚° (ì‹œê°í™”ìš©, YOLO ROI ì™¼ìª½ ìƒë‹¨ ëª¨ì„œë¦¬ì— ì •ë ¬)
            roi_size = 60       # ROI í¬ê¸° (ì •ì‚¬ê°í˜•)
            roi_x1 = yolo_roi_x1                    # 20
            roi_y1 = yolo_roi_y1                    # 42
            roi_x2 = roi_x1 + roi_size              # 80
            roi_y2 = roi_y1 + roi_size              # 102

            # YOLO ROI ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ì´ˆë¡ìƒ‰, ë¨¼ì € ê·¸ë ¤ì„œ ë’¤ì— í‘œì‹œ)
            cv2.rectangle(annotated_frame, (yolo_roi_x1, yolo_roi_y1), (yolo_roi_x2, yolo_roi_y2), (0, 255, 0), 2)
            cv2.putText(annotated_frame, "YOLO ROI", (yolo_roi_x1 + 10, yolo_roi_y1 + 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

            # í…œí”Œë¦¿ ROI ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ë…¸ë€ìƒ‰, ë‚˜ì¤‘ì— ê·¸ë ¤ì„œ ì•ì— í‘œì‹œ)
            cv2.rectangle(annotated_frame, (roi_x1, roi_y1), (roi_x2, roi_y2), (0, 255, 255), 3)
            cv2.putText(annotated_frame, "Template ROI", (roi_x1 + 10, roi_y1 + 50),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

            # í…œí”Œë¦¿ ë§¤ì¹­ ê²°ê³¼ ê·¸ë¦¬ê¸°
            if reference_point:
                ref_x, ref_y = reference_point

                # í…œí”Œë¦¿ ì˜ì—­ ê·¸ë¦¬ê¸° (ë³´ë¼ìƒ‰)
                template_h, template_w = template_alignment.template.shape[:2]
                top_left_x = ref_x - template_w // 2
                top_left_y = ref_y - template_h // 2
                cv2.rectangle(annotated_frame,
                            (top_left_x, top_left_y),
                            (top_left_x + template_w, top_left_y + template_h),
                            (255, 0, 255), 3)

                # ê¸°ì¤€ì  ì› ê·¸ë¦¬ê¸° (ë¹¨ê°„ìƒ‰)
                cv2.circle(annotated_frame, (ref_x, ref_y), 10, (0, 0, 255), -1)

                # ì¢Œí‘œì¶• ê·¸ë¦¬ê¸°
                cv2.arrowedLine(annotated_frame, (ref_x, ref_y), (ref_x + 50, ref_y), (255, 0, 0), 2)
                cv2.arrowedLine(annotated_frame, (ref_x, ref_y), (ref_x, ref_y + 50), (0, 255, 0), 2)

                # ROI ìƒíƒœ í…ìŠ¤íŠ¸
                status_text = "âœ… IN ROI" if roi_status == "in_roi" else "âš ï¸ OUT OF ROI"
                status_color = (0, 255, 0) if roi_status == "in_roi" else (0, 0, 255)
                cv2.putText(annotated_frame, status_text, (10, img_h - 10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, status_color, 2)

        gpio_pin = get_gpio_pin(defect_type)

        # ë·°ì–´ë¥¼ ìœ„í•´ ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ í”„ë ˆì„ ì €ì¥
        with frame_lock:
            latest_frames[camera_id] = annotated_frame

            # JPEG ì¸ì½”ë”© ë° ìºì‹± (WebSocket ì„±ëŠ¥ ìµœì í™”) â­
            encode_params = [
                cv2.IMWRITE_JPEG_QUALITY, 85,
                cv2.IMWRITE_JPEG_PROGRESSIVE, 0,
                cv2.IMWRITE_JPEG_OPTIMIZE, 1
            ]
            ret, buffer = cv2.imencode('.jpg', annotated_frame, encode_params)
            if ret:
                frame_base64 = base64.b64encode(buffer.tobytes()).decode('utf-8')
                latest_frames_jpeg[camera_id] = frame_base64
                logger.debug(f"[TEST] JPEG ìºì‹± ì™„ë£Œ: {camera_id} ({len(frame_base64)} bytes)")

                # ìµœì¢… í”„ë ˆì„ì„ viewerì— broadcast (ROI+í…œí”Œë¦¿+YOLO ë°•ì‹± ëª¨ë‘ í¬í•¨) â­â­â­
                socketio.emit('frame_update', {
                    'camera_id': camera_id,
                    'image': frame_base64,
                    'defect_type': defect_type,
                    'confidence': confidence,
                    'boxes_count': len(boxes_data),
                    'boxes_data': boxes_data,  # ì»´í¬ë„ŒíŠ¸ ìƒì„¸ ì •ë³´ ì¶”ê°€
                    'roi_status': roi_status,
                    'frame_shape': list(annotated_frame.shape),  # í”„ë ˆì„ í¬ê¸° [height, width, channels]
                    'timestamp': datetime.now().isoformat(),
                    'type': 'final_frame'
                })

                if should_run_yolo:
                    logger.info(f"[TEST] ìµœì¢… í”„ë ˆì„ broadcast: {camera_id} (YOLO: {len(boxes_data)}ê°œ ë¶€í’ˆ, ROI: {roi_status})")
                else:
                    logger.info(f"[TEST] ìµœì¢… í”„ë ˆì„ broadcast: {camera_id} (YOLO ê±´ë„ˆë›°ê¸°, ROI: {roi_status})")

        # 4. ì¶”ë¡  ì‹œê°„ ê³„ì‚°
        inference_time_ms = (time.time() - start_time) * 1000

        # 5. ì‘ë‹µ ìƒì„± (DB ì €ì¥ ìƒëµ)
        response = {
            'status': 'ok',
            'camera_id': camera_id,
            'defect_type': defect_type,
            'confidence': confidence,
            'gpio_pin': gpio_pin,
            'inference_time_ms': round(inference_time_ms, 2),
            'timestamp': datetime.now().isoformat(),
            'note': 'í…ŒìŠ¤íŠ¸ ëª¨ë“œ (DB ì €ì¥ ì•ˆ í•¨)'
        }

        # ë·°ì–´ë¥¼ ìœ„í•´ ê²°ê³¼ ì €ì¥
        with frame_lock:
            latest_results[camera_id] = response.copy()

        logger.info(f"[TEST] ì¶”ë¡  ì™„ë£Œ: {camera_id} â†’ {defect_type} (time: {inference_time_ms:.1f}ms)")
        return jsonify(response)

    except Exception as e:
        logger.error(f"[TEST] ì¶”ë¡  ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return jsonify({
            'status': 'error',
            'error': str(e)
        }), 500


@app.route('/predict', methods=['POST'])
def predict_single():
    """
    ë‹¨ì¼ í”„ë ˆì„ ì¶”ë¡  (ì¢Œì¸¡ ë˜ëŠ” ìš°ì¸¡)

    Request JSON:
        {
            "camera_id": "left" or "right",
            "image": "base64_encoded_jpeg_image"
        }

    Response JSON:
        {
            "status": "ok",
            "camera_id": "left",
            "defect_type": "ì •ìƒ" | "ë¶€í’ˆë¶ˆëŸ‰" | "ë‚©ë•œë¶ˆëŸ‰" | "íê¸°",
            "confidence": 0.95,
            "inference_time_ms": 85.3,
            "timestamp": "2025-01-27T15:30:45.123456"
        }
    """
    start_time = time.time()

    try:
        # 1. ìš”ì²­ ë°ì´í„° ê²€ì¦
        data = request.get_json()
        if not data:
            logger.error("ìš”ì²­ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ")
            return jsonify({
                'status': 'error',
                'error': 'Request body is empty'
            }), 400

        camera_id = data.get('camera_id')
        image_base64 = data.get('image')

        if not camera_id or not image_base64:
            logger.error(f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: camera_id={camera_id}, image={'ìˆìŒ' if image_base64 else 'ì—†ìŒ'}")
            return jsonify({
                'status': 'error',
                'error': 'Missing required fields: camera_id, image'
            }), 400

        # 2. Base64 ë””ì½”ë”© ë° í”„ë ˆì„ ê²€ì¦
        try:
            image_bytes = base64.b64decode(image_base64)
            nparr = np.frombuffer(image_bytes, np.uint8)
            frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

            if frame is None or frame.size == 0:
                logger.error("í”„ë ˆì„ ë””ì½”ë”© ì‹¤íŒ¨: ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ ë°ì´í„°")
                return jsonify({
                    'status': 'error',
                    'error': 'Invalid image data: failed to decode'
                }), 400

            logger.info(f"í”„ë ˆì„ ìˆ˜ì‹  ì„±ê³µ: {camera_id} (shape: {frame.shape})")

        except Exception as decode_error:
            logger.error(f"Base64 ë””ì½”ë”© ì‹¤íŒ¨: {decode_error}")
            return jsonify({
                'status': 'error',
                'error': f'Failed to decode image: {str(decode_error)}'
            }), 400

        # 3. AI ì¶”ë¡  (YOLO ëª¨ë¸)
        if yolo_model is not None:
            try:
                # YOLO ì¶”ë¡  ì‹¤í–‰
                results = yolo_model(frame, verbose=False)
                defect_type, confidence, boxes = parse_yolo_results(results)
                logger.info(f"YOLO ì¶”ë¡  ì™„ë£Œ: {len(boxes)}ê°œ ê°ì²´ ê²€ì¶œ")
            except Exception as yolo_error:
                logger.error(f"YOLO ì¶”ë¡  ì‹¤íŒ¨: {yolo_error}")
                # ì¶”ë¡  ì‹¤íŒ¨ ì‹œ ë”ë¯¸ ê°’ ì‚¬ìš©
                defect_type = "ì •ìƒ"
                confidence = 0.0
                boxes = []
        else:
            # ëª¨ë¸ ë¯¸ë¡œë“œ ì‹œ ë”ë¯¸ ì‘ë‹µ
            logger.warning("YOLO ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ - ë”ë¯¸ ê²°ê³¼ ë°˜í™˜")
            defect_type = "ì •ìƒ"
            confidence = 0.95
            boxes = []

        # 4. GPIO í•€ ê²°ì •
        gpio_pin = get_gpio_pin(defect_type)

        # 5. ì¶”ë¡  ì‹œê°„ ê³„ì‚°
        inference_time_ms = (time.time() - start_time) * 1000

        # 6. ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
        try:
            inspection_id = db.insert_inspection(
                camera_id=camera_id,
                defect_type=defect_type,
                confidence=confidence,
                boxes=boxes,
                gpio_pin=gpio_pin,
                image_path=None  # ì´ë¯¸ì§€ ì €ì¥ ê¸°ëŠ¥ ì¶”ê°€ ì‹œ ê²½ë¡œ ì§€ì •
            )
            logger.info(f"ê²€ì‚¬ ì´ë ¥ ì €ì¥ ì™„ë£Œ (ID: {inspection_id})")
        except Exception as db_error:
            logger.warning(f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨ (ì¶”ë¡ ì€ ê³„ì† ì§„í–‰): {db_error}")
            # DB ì €ì¥ ì‹¤íŒ¨í•´ë„ ì¶”ë¡  ê²°ê³¼ëŠ” ë°˜í™˜

        # 7. ì‘ë‹µ ìƒì„±
        response = {
            'status': 'ok',
            'camera_id': camera_id,
            'defect_type': defect_type,
            'confidence': confidence,
            'gpio_pin': gpio_pin,
            'inference_time_ms': round(inference_time_ms, 2),
            'timestamp': datetime.now().isoformat()
        }

        logger.info(f"ì¶”ë¡  ì™„ë£Œ: {camera_id} â†’ {defect_type} (confidence: {confidence:.2f}, GPIO: {gpio_pin}, time: {inference_time_ms:.1f}ms)")
        return jsonify(response)

    except Exception as e:
        logger.error(f"ì¶”ë¡  ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return jsonify({
            'status': 'error',
            'error': str(e)
        }), 500


@app.route('/predict_dual', methods=['POST'])
def predict_dual():
    """
    ì–‘ë©´ ë™ì‹œ ì¶”ë¡  (ì¢Œì¸¡ + ìš°ì¸¡)

    Request JSON:
        {
            "left_image": "base64_encoded_jpeg_image",
            "right_image": "base64_encoded_jpeg_image"
        }

    Response JSON:
        {
            "status": "ok",
            "final_defect_type": "ë‚©ë•œë¶ˆëŸ‰",
            "final_confidence": 0.92,
            "left_result": {...},
            "right_result": {...},
            "gpio_signal": {
                "pin": 27,
                "duration_ms": 300
            },
            "robot_command": {
                "category": "SOLDER_DEFECT",
                "slot": 1
            }
        }
    """
    start_time = time.time()

    try:
        # 1. ìš”ì²­ ë°ì´í„° ê²€ì¦
        data = request.get_json()
        if not data:
            logger.error("ìš”ì²­ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ")
            return jsonify({
                'status': 'error',
                'error': 'Request body is empty'
            }), 400

        left_image = data.get('left_image')
        right_image = data.get('right_image')

        if not left_image or not right_image:
            logger.error(f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: left_image={'ìˆìŒ' if left_image else 'ì—†ìŒ'}, right_image={'ìˆìŒ' if right_image else 'ì—†ìŒ'}")
            return jsonify({
                'status': 'error',
                'error': 'Missing required fields: left_image, right_image'
            }), 400

        # 2. ì¢Œì¸¡ í”„ë ˆì„ ì²˜ë¦¬
        try:
            left_bytes = base64.b64decode(left_image)
            left_nparr = np.frombuffer(left_bytes, np.uint8)
            left_frame = cv2.imdecode(left_nparr, cv2.IMREAD_COLOR)

            if left_frame is None or left_frame.size == 0:
                raise ValueError("ì¢Œì¸¡ í”„ë ˆì„ ë””ì½”ë”© ì‹¤íŒ¨")

            logger.info(f"ì¢Œì¸¡ í”„ë ˆì„ ìˆ˜ì‹  ì„±ê³µ (shape: {left_frame.shape})")
        except Exception as e:
            logger.error(f"ì¢Œì¸¡ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return jsonify({
                'status': 'error',
                'error': f'Failed to process left image: {str(e)}'
            }), 400

        # 3. ìš°ì¸¡ í”„ë ˆì„ ì²˜ë¦¬
        try:
            right_bytes = base64.b64decode(right_image)
            right_nparr = np.frombuffer(right_bytes, np.uint8)
            right_frame = cv2.imdecode(right_nparr, cv2.IMREAD_COLOR)

            if right_frame is None or right_frame.size == 0:
                raise ValueError("ìš°ì¸¡ í”„ë ˆì„ ë””ì½”ë”© ì‹¤íŒ¨")

            logger.info(f"ìš°ì¸¡ í”„ë ˆì„ ìˆ˜ì‹  ì„±ê³µ (shape: {right_frame.shape})")
        except Exception as e:
            logger.error(f"ìš°ì¸¡ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return jsonify({
                'status': 'error',
                'error': f'Failed to process right image: {str(e)}'
            }), 400

        # 4. PCB ì •ë ¬ ë° AI ì¶”ë¡ 
        alignment_time_start = time.time()

        # 4-1. ì¢Œì¸¡ PCB ì •ë ¬
        left_aligned_frame = left_frame
        left_alignment_info = {'method': 'none', 'success': False}

        if pcb_aligner_left is not None:
            left_align_result = pcb_aligner_left.process_frame(left_frame, debug=False)

            if left_align_result['success']:
                left_aligned_frame = left_align_result['aligned_frame']
                left_alignment_info = {
                    'method': left_align_result['method'],
                    'success': True
                }
                logger.info(f"ì¢Œì¸¡ PCB ì •ë ¬ ì„±ê³µ (ë°©ë²•: {left_align_result['method']})")
            else:
                logger.warning(f"ì¢Œì¸¡ PCB ì •ë ¬ ì‹¤íŒ¨: {left_align_result.get('error', 'Unknown')}")
                left_alignment_info['error'] = left_align_result.get('error')

        # 4-2. ìš°ì¸¡ PCB ì •ë ¬
        right_aligned_frame = right_frame
        right_alignment_info = {'method': 'none', 'success': False}

        if pcb_aligner_right is not None:
            right_align_result = pcb_aligner_right.process_frame(right_frame, debug=False)

            if right_align_result['success']:
                right_aligned_frame = right_align_result['aligned_frame']
                right_alignment_info = {
                    'method': right_align_result['method'],
                    'success': True
                }
                logger.info(f"ìš°ì¸¡ PCB ì •ë ¬ ì„±ê³µ (ë°©ë²•: {right_align_result['method']})")
            else:
                logger.warning(f"ìš°ì¸¡ PCB ì •ë ¬ ì‹¤íŒ¨: {right_align_result.get('error', 'Unknown')}")
                right_alignment_info['error'] = right_align_result.get('error')

        alignment_time = (time.time() - alignment_time_start) * 1000  # ms
        logger.info(f"PCB ì •ë ¬ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {alignment_time:.2f}ms)")

        # 4-3. YOLO ì¶”ë¡  (ì •ë ¬ëœ í”„ë ˆì„)
        inference_time_start = time.time()

        left_detections = []
        right_detections = []

        if yolo_model is not None:
            # ì¢Œì¸¡ YOLO ì¶”ë¡ 
            left_yolo_results = yolo_model.predict(left_aligned_frame, conf=0.25, verbose=False)
            if len(left_yolo_results) > 0 and len(left_yolo_results[0].boxes) > 0:
                boxes = left_yolo_results[0].boxes
                for box in boxes:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2
                    class_id = int(box.cls[0])
                    class_name = yolo_model.names[class_id]
                    confidence = float(box.conf[0])

                    left_detections.append({
                        'class_name': class_name,
                        'bbox': [float(x1), float(y1), float(x2), float(y2)],
                        'center': [float(cx), float(cy)],
                        'confidence': confidence
                    })

            # ìš°ì¸¡ YOLO ì¶”ë¡ 
            right_yolo_results = yolo_model.predict(right_aligned_frame, conf=0.25, verbose=False)
            if len(right_yolo_results) > 0 and len(right_yolo_results[0].boxes) > 0:
                boxes = right_yolo_results[0].boxes
                for box in boxes:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2
                    class_id = int(box.cls[0])
                    class_name = yolo_model.names[class_id]
                    confidence = float(box.conf[0])

                    right_detections.append({
                        'class_name': class_name,
                        'bbox': [float(x1), float(y1), float(x2), float(y2)],
                        'center': [float(cx), float(cy)],
                        'confidence': confidence
                    })

        inference_time = (time.time() - inference_time_start) * 1000  # ms
        logger.info(f"YOLO ì¶”ë¡  ì™„ë£Œ (ì¢Œ: {len(left_detections)}ê°œ, ìš°: {len(right_detections)}ê°œ, ì†Œìš” ì‹œê°„: {inference_time:.2f}ms)")

        # 4-4. ì»´í¬ë„ŒíŠ¸ ìœ„ì¹˜ ê²€ì¦
        verification_time_start = time.time()

        left_verification = None
        right_verification = None

        if component_verifier_left is not None and left_alignment_info['success']:
            left_verification = component_verifier_left.verify_components(left_detections, debug=False)
            logger.info(f"ì¢Œì¸¡ ì»´í¬ë„ŒíŠ¸ ê²€ì¦ ì™„ë£Œ: ì •ìƒ {left_verification['summary']['correct_count']}ê°œ, "
                       f"ìœ„ì¹˜ì˜¤ë¥˜ {left_verification['summary']['misplaced_count']}ê°œ, "
                       f"ëˆ„ë½ {left_verification['summary']['missing_count']}ê°œ")

        if component_verifier_right is not None and right_alignment_info['success']:
            right_verification = component_verifier_right.verify_components(right_detections, debug=False)
            logger.info(f"ìš°ì¸¡ ì»´í¬ë„ŒíŠ¸ ê²€ì¦ ì™„ë£Œ: ì •ìƒ {right_verification['summary']['correct_count']}ê°œ, "
                       f"ìœ„ì¹˜ì˜¤ë¥˜ {right_verification['summary']['misplaced_count']}ê°œ, "
                       f"ëˆ„ë½ {right_verification['summary']['missing_count']}ê°œ")

        verification_time = (time.time() - verification_time_start) * 1000  # ms
        logger.info(f"ì»´í¬ë„ŒíŠ¸ ê²€ì¦ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {verification_time:.2f}ms)")

        # 4-5. ìµœì¢… ë¶ˆëŸ‰ íŒì •
        final_defect_type = "ì •ìƒ"
        final_confidence = 0.95

        # ì¹˜ëª…ì  ë¶ˆëŸ‰ ì²´í¬
        if left_verification is not None:
            is_critical, reason = component_verifier_left.is_critical_defect(left_verification)
            if is_critical:
                final_defect_type = "ë¶€í’ˆë¶ˆëŸ‰"
                final_confidence = 0.85
                logger.warning(f"ì¢Œì¸¡ ì¹˜ëª…ì  ë¶ˆëŸ‰: {reason}")

        if right_verification is not None:
            is_critical, reason = component_verifier_right.is_critical_defect(right_verification)
            if is_critical:
                final_defect_type = "ë¶€í’ˆë¶ˆëŸ‰"
                final_confidence = 0.85
                logger.warning(f"ìš°ì¸¡ ì¹˜ëª…ì  ë¶ˆëŸ‰: {reason}")

        # ê²°ê³¼ êµ¬ì¡°í™”
        left_result = {
            'defect_type': final_defect_type if left_verification and component_verifier_left.is_critical_defect(left_verification)[0] else 'ì •ìƒ',
            'confidence': final_confidence,
            'boxes': left_detections,
            'alignment': left_alignment_info,
            'verification': left_verification
        }

        right_result = {
            'defect_type': final_defect_type if right_verification and component_verifier_right.is_critical_defect(right_verification)[0] else 'ì •ìƒ',
            'confidence': final_confidence,
            'boxes': right_detections,
            'alignment': right_alignment_info,
            'verification': right_verification
        }

        # 5. GPIO í•€ ê²°ì •
        gpio_pin = get_gpio_pin(final_defect_type)

        # 6. ë°•ìŠ¤ ì¹´í…Œê³ ë¦¬ ë° ìŠ¬ë¡¯ ê²°ì •
        category = defect_type_to_category(final_defect_type)

        # í˜„ì¬ ë°•ìŠ¤ ìƒíƒœ ì¡°íšŒ
        try:
            box_status = db.get_box_status(category)
            if box_status and not box_status['is_full']:
                current_slot = box_status['current_slot']
                # ë°•ìŠ¤ ìƒíƒœ ì—…ë°ì´íŠ¸ (ìŠ¬ë¡¯ ì¦ê°€)
                db.update_box_status(category, increment=True)
                logger.info(f"ë°•ìŠ¤ ìŠ¬ë¡¯ ì—…ë°ì´íŠ¸: {category} (slot {current_slot} â†’ {current_slot + 1})")
            else:
                current_slot = 0
                logger.warning(f"ë°•ìŠ¤ ê°€ë“ ì°¸: {category}")
        except Exception as db_error:
            logger.warning(f"ë°•ìŠ¤ ìƒíƒœ ì¡°íšŒ/ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {db_error}")
            current_slot = 0

        # 7. ì–‘ì¸¡ ê²€ì‚¬ ì´ë ¥ ì €ì¥
        try:
            # ì¢Œì¸¡ ê²€ì‚¬ ì´ë ¥
            left_inspection_id = db.insert_inspection(
                camera_id='left',
                defect_type=left_result['defect_type'],
                confidence=left_result['confidence'],
                boxes=left_result['boxes'],
                gpio_pin=gpio_pin
            )

            # ìš°ì¸¡ ê²€ì‚¬ ì´ë ¥
            right_inspection_id = db.insert_inspection(
                camera_id='right',
                defect_type=right_result['defect_type'],
                confidence=right_result['confidence'],
                boxes=right_result['boxes'],
                gpio_pin=gpio_pin
            )

            logger.info(f"ì–‘ë©´ ê²€ì‚¬ ì´ë ¥ ì €ì¥ ì™„ë£Œ (left: {left_inspection_id}, right: {right_inspection_id})")
        except Exception as db_error:
            logger.warning(f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {db_error}")

        # 8. ì¶”ë¡  ì‹œê°„ ê³„ì‚°
        inference_time_ms = (time.time() - start_time) * 1000

        # 9. ì‘ë‹µ ìƒì„±
        response = {
            'status': 'ok',
            'final_defect_type': final_defect_type,
            'final_confidence': final_confidence,
            'left_result': left_result,
            'right_result': right_result,
            'gpio_signal': {
                'pin': gpio_pin,
                'duration_ms': 300
            },
            'robot_command': {
                'category': category,
                'slot': current_slot
            },
            'inference_time_ms': round(inference_time_ms, 2),
            'timestamp': datetime.now().isoformat()
        }

        logger.info(f"ì–‘ë©´ ì¶”ë¡  ì™„ë£Œ: {final_defect_type} (confidence: {final_confidence:.2f}, GPIO: {gpio_pin}, slot: {current_slot}, time: {inference_time_ms:.1f}ms)")
        return jsonify(response)

    except Exception as e:
        logger.error(f"ì–‘ë©´ ì¶”ë¡  ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return jsonify({
            'status': 'error',
            'error': str(e)
        }), 500


@app.route('/box_status', methods=['GET'])
def get_box_status():
    """
    ë°•ìŠ¤ ìƒíƒœ ì¡°íšŒ (C# WinForms ëª¨ë‹ˆí„°ë§ìš©)

    Response JSON:
        {
            "status": "ok",
            "boxes": [
                {
                    "box_id": "NORMAL",
                    "current_slot": 3,
                    "max_slots": 5,
                    "is_full": false,
                    "total_pcb_count": 15
                },
                ...
            ],
            "summary": {
                "total_boxes": 3,
                "full_boxes": 0,
                "system_stopped": false
            }
        }
    """
    try:
        # MySQLì—ì„œ ë°•ìŠ¤ ìƒíƒœ ì¡°íšŒ
        boxes = db.get_all_box_status()

        if not boxes:
            logger.warning("ë°•ìŠ¤ ìƒíƒœ ë°ì´í„°ê°€ ì—†ìŒ - ì´ˆê¸° ë°ì´í„° í™•ì¸ í•„ìš”")
            return jsonify({
                'status': 'error',
                'error': 'No box status data found in database'
            }), 404

        # summary í†µê³„ ê³„ì‚°
        summary = {
            'total_boxes': len(boxes),
            'full_boxes': sum(1 for box in boxes if box['is_full']),
            'empty_boxes': sum(1 for box in boxes if box['current_slot'] == 0),
            'system_stopped': all(box['is_full'] for box in boxes)
        }

        logger.info(f"ë°•ìŠ¤ ìƒíƒœ ì¡°íšŒ ì™„ë£Œ: {summary['total_boxes']}ê°œ ë°•ìŠ¤, {summary['full_boxes']}ê°œ ê°€ë“ì°¸")

        return jsonify({
            'status': 'ok',
            'boxes': boxes,
            'summary': summary
        })

    except Exception as e:
        logger.error(f"ë°•ìŠ¤ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return jsonify({
            'status': 'error',
            'error': str(e)
        }), 500


@app.route('/viewer', methods=['GET'])
def viewer():
    """ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ë·°ì–´ í˜ì´ì§€"""
    html_template = """
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>PCB ê²€ì‚¬ ì‹¤ì‹œê°„ ë·°ì–´</title>
        <style>
            * { margin: 0; padding: 0; box-sizing: border-box; }
            body {
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
                background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
                color: #fff;
                padding: 20px;
            }
            .container {
                max-width: 1400px;
                margin: 0 auto;
            }
            h1 {
                text-align: center;
                margin-bottom: 30px;
                font-size: 2.5em;
                text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
            }
            .cameras {
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(500px, 1fr));
                gap: 30px;
                margin-bottom: 30px;
            }
            .camera-box {
                background: rgba(255,255,255,0.1);
                border-radius: 15px;
                padding: 20px;
                backdrop-filter: blur(10px);
                box-shadow: 0 8px 32px rgba(0,0,0,0.3);
            }
            .camera-title {
                font-size: 1.5em;
                margin-bottom: 15px;
                text-align: center;
                font-weight: bold;
            }
            .camera-stream {
                width: 100%;
                border-radius: 10px;
                background: #000;
                min-height: 400px;
                display: flex;
                align-items: center;
                justify-content: center;
                font-size: 1.2em;
                color: #aaa;
            }
            .camera-stream img {
                width: 100%;
                border-radius: 10px;
            }
            .camera-info {
                margin-top: 15px;
                padding: 15px;
                background: rgba(0,0,0,0.3);
                border-radius: 10px;
            }
            .info-row {
                display: flex;
                justify-content: space-between;
                margin: 8px 0;
                font-size: 1.1em;
            }
            .info-label {
                font-weight: bold;
                color: #aaf;
            }
            .status-ok { color: #4f4; }
            .status-defect { color: #f44; }
            .footer {
                text-align: center;
                margin-top: 20px;
                opacity: 0.7;
            }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸ” PCB ê²€ì‚¬ ì‹¤ì‹œê°„ ë·°ì–´</h1>

            <div class="cameras">
                <div class="camera-box">
                    <div class="camera-title">ğŸ“· ì¢Œì¸¡ ì¹´ë©”ë¼ (Left)</div>
                    <div class="camera-stream">
                        <img id="left-stream" src="/video_feed/left" alt="ì¢Œì¸¡ ì¹´ë©”ë¼" onerror="this.style.display='none'; this.parentElement.innerText='ì¹´ë©”ë¼ ì—°ê²° ëŒ€ê¸° ì¤‘...'">
                    </div>
                    <div class="camera-info">
                        <div class="info-row">
                            <span class="info-label">íŒì •:</span>
                            <span id="left-defect" class="status-ok">-</span>
                        </div>
                        <div class="info-row">
                            <span class="info-label">ì‹ ë¢°ë„:</span>
                            <span id="left-confidence">-</span>
                        </div>
                        <div class="info-row">
                            <span class="info-label">ì²˜ë¦¬ì‹œê°„:</span>
                            <span id="left-time">-</span>
                        </div>
                    </div>
                </div>

                <div class="camera-box">
                    <div class="camera-title">ğŸ“· ìš°ì¸¡ ì¹´ë©”ë¼ (Right)</div>
                    <div class="camera-stream">
                        <img id="right-stream" src="/video_feed/right" alt="ìš°ì¸¡ ì¹´ë©”ë¼" onerror="this.style.display='none'; this.parentElement.innerText='ì¹´ë©”ë¼ ì—°ê²° ëŒ€ê¸° ì¤‘...'">
                    </div>
                    <div class="camera-info">
                        <div class="info-row">
                            <span class="info-label">íŒì •:</span>
                            <span id="right-defect" class="status-ok">-</span>
                        </div>
                        <div class="info-row">
                            <span class="info-label">ì‹ ë¢°ë„:</span>
                            <span id="right-confidence">-</span>
                        </div>
                        <div class="info-row">
                            <span class="info-label">ì²˜ë¦¬ì‹œê°„:</span>
                            <span id="right-time">-</span>
                        </div>
                    </div>
                </div>
            </div>

            <div class="footer">
                âœ¨ PCB ë¶ˆëŸ‰ ê²€ì‚¬ ì‹œìŠ¤í…œ v1.0 | Flask Server | Real-time Streaming
            </div>
        </div>

        <script>
            // 1ì´ˆë§ˆë‹¤ ê²°ê³¼ ì •ë³´ ì—…ë°ì´íŠ¸
            function updateResults() {
                fetch('/api/latest_results')
                    .then(res => res.json())
                    .then(data => {
                        // ì¢Œì¸¡ ì¹´ë©”ë¼
                        if (data.left && data.left.defect_type) {
                            document.getElementById('left-defect').textContent = data.left.defect_type;
                            document.getElementById('left-defect').className = data.left.defect_type === 'ì •ìƒ' ? 'status-ok' : 'status-defect';
                            document.getElementById('left-confidence').textContent = (data.left.confidence * 100).toFixed(1) + '%';
                            document.getElementById('left-time').textContent = data.left.inference_time_ms.toFixed(1) + 'ms';
                        }

                        // ìš°ì¸¡ ì¹´ë©”ë¼
                        if (data.right && data.right.defect_type) {
                            document.getElementById('right-defect').textContent = data.right.defect_type;
                            document.getElementById('right-defect').className = data.right.defect_type === 'ì •ìƒ' ? 'status-ok' : 'status-defect';
                            document.getElementById('right-confidence').textContent = (data.right.confidence * 100).toFixed(1) + '%';
                            document.getElementById('right-time').textContent = data.right.inference_time_ms.toFixed(1) + 'ms';
                        }
                    })
                    .catch(err => console.error('ê²°ê³¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:', err));
            }

            // 1ì´ˆë§ˆë‹¤ ì—…ë°ì´íŠ¸
            setInterval(updateResults, 1000);
            updateResults();
        </script>
    </body>
    </html>
    """
    return render_template_string(html_template)


@app.route('/debug_viewer', methods=['GET'])
def debug_viewer():
    """í…œí”Œë¦¿ ë§¤ì¹­ ë””ë²„ê·¸ ë·°ì–´ (WebSocket ê¸°ë°˜)"""
    html_template = """
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>í…œí”Œë¦¿ ë§¤ì¹­ ë””ë²„ê·¸ ë·°ì–´</title>
        <script src="https://cdn.socket.io/4.5.4/socket.io.min.js"></script>
        <style>
            * { margin: 0; padding: 0; box-sizing: border-box; }
            body {
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                color: #fff;
                padding: 20px;
            }
            .container {
                max-width: 1400px;
                margin: 0 auto;
            }
            h1 {
                text-align: center;
                margin-bottom: 30px;
                font-size: 2.5em;
                text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
            }
            .info-panel {
                background: rgba(255,255,255,0.1);
                border-radius: 15px;
                padding: 20px;
                margin-bottom: 30px;
                backdrop-filter: blur(10px);
                box-shadow: 0 8px 32px rgba(0,0,0,0.3);
            }
            .info-grid {
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
                gap: 20px;
            }
            .info-item {
                background: rgba(255,255,255,0.05);
                padding: 15px;
                border-radius: 10px;
            }
            .info-value {
                font-size: 1.5em;
                color: #4CAF50;
                text-align: center;
            }
            .camera-box {
                background: rgba(255,255,255,0.1);
                border-radius: 15px;
                padding: 20px;
                backdrop-filter: blur(10px);
                box-shadow: 0 8px 32px rgba(0,0,0,0.3);
                margin-bottom: 20px;
            }
            .camera-title {
                font-size: 1.8em;
                margin-bottom: 15px;
                text-align: center;
                font-weight: bold;
            }
            .camera-stream {
                width: 100%;
                border-radius: 10px;
                background: #000;
                min-height: 480px;
                display: flex;
                align-items: center;
                justify-content: center;
            }
            .camera-stream img {
                width: 100%;
                border-radius: 10px;
            }
            .footer {
                text-align: center;
                margin-top: 20px;
                opacity: 0.7;
            }
            .components-panel {
                background: rgba(255,255,255,0.1);
                border-radius: 15px;
                padding: 20px;
                margin-top: 20px;
                backdrop-filter: blur(10px);
                box-shadow: 0 8px 32px rgba(0,0,0,0.3);
            }
            .table-container {
                overflow-x: auto;
                border-radius: 10px;
                background: rgba(0,0,0,0.3);
            }
            #components-table {
                width: 100%;
                border-collapse: collapse;
                text-align: left;
            }
            #components-table th {
                background: rgba(255,255,255,0.2);
                padding: 12px;
                font-weight: bold;
                border-bottom: 2px solid rgba(255,255,255,0.3);
            }
            #components-table td {
                padding: 10px 12px;
                border-bottom: 1px solid rgba(255,255,255,0.1);
            }
            #components-table tbody tr:hover {
                background: rgba(255,255,255,0.05);
            }
            .save-btn {
                display: block;
                width: 100%;
                max-width: 400px;
                margin: 20px auto 0;
                padding: 15px 30px;
                font-size: 1.2em;
                font-weight: bold;
                color: #fff;
                background: linear-gradient(135deg, #4CAF50 0%, #45a049 100%);
                border: none;
                border-radius: 10px;
                cursor: pointer;
                box-shadow: 0 4px 15px rgba(76, 175, 80, 0.4);
                transition: all 0.3s ease;
            }
            .save-btn:hover {
                transform: translateY(-2px);
                box-shadow: 0 6px 20px rgba(76, 175, 80, 0.6);
            }
            .save-btn:active {
                transform: translateY(0);
            }
            .save-btn:disabled {
                background: rgba(150, 150, 150, 0.5);
                cursor: not-allowed;
                box-shadow: none;
            }
            .notification {
                position: fixed;
                top: 20px;
                right: 20px;
                padding: 15px 25px;
                border-radius: 10px;
                font-weight: bold;
                box-shadow: 0 4px 15px rgba(0,0,0,0.3);
                z-index: 1000;
                display: none;
                animation: slideIn 0.3s ease;
            }
            .notification.success {
                background: #4CAF50;
                color: #fff;
            }
            .notification.error {
                background: #f44336;
                color: #fff;
            }
            @keyframes slideIn {
                from {
                    transform: translateX(400px);
                    opacity: 0;
                }
                to {
                    transform: translateX(0);
                    opacity: 1;
                }
            }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸ¯ í…œí”Œë¦¿ ë§¤ì¹­ ë””ë²„ê·¸ ë·°ì–´</h1>

            <div class="info-panel">
                <div class="info-grid">
                    <div class="info-item">
                        <div class="info-label">ê¸°ì¤€ì  ìœ„ì¹˜</div>
                        <div class="info-value" id="reference-point">-</div>
                    </div>
                    <div class="info-item">
                        <div class="info-label">ROI ìƒíƒœ</div>
                        <div class="info-value" id="confidence">-</div>
                    </div>
                    <div class="info-item">
                        <div class="info-label">ê²€ì¶œ ê°œìˆ˜</div>
                        <div class="info-value" id="template-size">-</div>
                    </div>
                    <div class="info-item">
                        <div class="info-label">í”„ë ˆì„ í¬ê¸°</div>
                        <div class="info-value" id="frame-size">-</div>
                    </div>
                </div>
            </div>

            <div class="camera-box">
                <div class="camera-title">ğŸ“· ì¢Œì¸¡ ì¹´ë©”ë¼ (ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° + ROI ê¸°ë°˜ YOLO)</div>
                <div class="camera-stream">
                    <img id="camera-stream" alt="í…œí”Œë¦¿ ë§¤ì¹­ ê²°ê³¼" style="display:none;">
                    <div id="loading-text">í”„ë ˆì„ ëŒ€ê¸° ì¤‘...</div>
                </div>
            </div>

            <div class="components-panel" style="display:none;" id="components-panel">
                <h2 style="text-align: center; margin-bottom: 20px;">ğŸ” ê²€ì¶œëœ ì»´í¬ë„ŒíŠ¸ ìƒì„¸ ì •ë³´</h2>
                <div class="table-container">
                    <table id="components-table">
                        <thead>
                            <tr>
                                <th>#</th>
                                <th>ë¶€í’ˆ íƒ€ì…</th>
                                <th>ì ˆëŒ€ ì¢Œí‘œ (X, Y)</th>
                                <th>ìƒëŒ€ ì¢Œí‘œ (ê¸°ì¤€ì  0,0)</th>
                                <th>ë°”ìš´ë”© ë°•ìŠ¤ (X1, Y1, X2, Y2)</th>
                                <th>ì‹ ë¢°ë„</th>
                            </tr>
                        </thead>
                        <tbody id="components-tbody">
                            <tr><td colspan="6" style="text-align: center;">ê²€ì¶œëœ ì»´í¬ë„ŒíŠ¸ ì—†ìŒ</td></tr>
                        </tbody>
                    </table>
                </div>
                <button class="save-btn" id="save-components-btn" onclick="saveReferenceComponents()" disabled>
                    ğŸ’¾ ê¸°ì¤€ ë¶€í’ˆ ë°°ì¹˜ ì €ì¥ (ì œí’ˆ ì½”ë“œ: BC)
                </button>
            </div>

            <div class="footer">
                âœ¨ í…œí”Œë¦¿ ë§¤ì¹­ ë””ë²„ê·¸ ì‹œìŠ¤í…œ v2.0 | Flask Server | WebSocket Real-time
            </div>
        </div>

        <!-- ì•Œë¦¼ ë©”ì‹œì§€ -->
        <div id="notification" class="notification"></div>

        <script>
            // WebSocket ì—°ê²°
            const socket = io();

            // WebSocket ì—°ê²° ì´ë²¤íŠ¸
            socket.on('connect', () => {
                console.log('âœ… WebSocket ì—°ê²° ì„±ê³µ');
            });

            socket.on('disconnect', () => {
                console.log('âŒ WebSocket ì—°ê²° ì¢…ë£Œ');
            });

            socket.on('connect_error', (error) => {
                console.error('âŒ WebSocket ì—°ê²° ì˜¤ë¥˜:', error);
            });

            // DOM ìš”ì†Œ
            const imgElement = document.getElementById('camera-stream');
            const loadingText = document.getElementById('loading-text');
            const refPointElement = document.getElementById('reference-point');
            const confidenceElement = document.getElementById('confidence');
            const templateSizeElement = document.getElementById('template-size');
            const frameSizeElement = document.getElementById('frame-size');
            const saveBtn = document.getElementById('save-components-btn');
            const notification = document.getElementById('notification');

            // í˜„ì¬ ê²€ì¶œëœ ì»´í¬ë„ŒíŠ¸ ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ì „ì—­ ë³€ìˆ˜
            let currentComponentsData = [];

            // í”„ë ˆì„ ì—…ë°ì´íŠ¸ ìˆ˜ì‹  (ëª¨ë“  ì •ë³´ í¬í•¨)
            socket.on('frame_update', (data) => {
                console.log('ğŸ“¥ í”„ë ˆì„ ì—…ë°ì´íŠ¸ ìˆ˜ì‹ :', data.camera_id, data);

                if (data.camera_id === 'left') {
                    // ì´ë¯¸ì§€ ì—…ë°ì´íŠ¸
                    if (data.image) {
                        imgElement.src = 'data:image/jpeg;base64,' + data.image;
                        imgElement.style.display = 'block';
                        loadingText.style.display = 'none';
                    }

                    // ROI ìƒíƒœ ì—…ë°ì´íŠ¸
                    if (data.roi_status) {
                        if (data.roi_status === 'in_roi') {
                            confidenceElement.textContent = 'âœ… ROI ì•ˆ';
                            confidenceElement.style.color = '#4CAF50';
                        } else if (data.roi_status === 'out_of_roi') {
                            confidenceElement.textContent = 'âš ï¸ ROI ë°–';
                            confidenceElement.style.color = '#FFC107';
                        } else {
                            confidenceElement.textContent = data.roi_status;
                            confidenceElement.style.color = '#FFF';
                        }
                    }

                    // ê²€ì¶œ ê°œìˆ˜ ì—…ë°ì´íŠ¸
                    if (data.boxes_count !== undefined) {
                        templateSizeElement.textContent = `${data.boxes_count}ê°œ`;
                        templateSizeElement.style.color = data.boxes_count > 0 ? '#4CAF50' : '#FFF';
                    }

                    // í”„ë ˆì„ í¬ê¸° ì—…ë°ì´íŠ¸
                    if (data.frame_shape) {
                        const [height, width, channels] = data.frame_shape;
                        frameSizeElement.textContent = `${width}x${height}`;
                    }

                    // ì»´í¬ë„ŒíŠ¸ ìƒì„¸ ì •ë³´ ì—…ë°ì´íŠ¸
                    const componentsData = data.boxes_data || [];
                    currentComponentsData = componentsData;  // ì „ì—­ ë³€ìˆ˜ì— ì €ì¥
                    updateComponentsTable(componentsData);

                    // ì €ì¥ ë²„íŠ¼ í™œì„±í™”/ë¹„í™œì„±í™”
                    if (componentsData.length > 0) {
                        saveBtn.disabled = false;
                    } else {
                        saveBtn.disabled = true;
                    }
                }
            });

            // ì»´í¬ë„ŒíŠ¸ í…Œì´ë¸” ì—…ë°ì´íŠ¸ í•¨ìˆ˜
            function updateComponentsTable(components) {
                const tbody = document.getElementById('components-tbody');
                const panel = document.getElementById('components-panel');

                if (!components || components.length === 0) {
                    tbody.innerHTML = '<tr><td colspan="6" style="text-align: center;">ê²€ì¶œëœ ì»´í¬ë„ŒíŠ¸ ì—†ìŒ</td></tr>';
                    panel.style.display = 'none';
                    return;
                }

                panel.style.display = 'block';
                tbody.innerHTML = '';

                components.forEach((comp, index) => {
                    const row = tbody.insertRow();

                    // ìƒëŒ€ ì¢Œí‘œ í‘œì‹œ (ê¸°ì¤€ì  ê¸°ì¤€)
                    let relativeCoordsHtml = '-';
                    if (comp.relative_center) {
                        const relX = Math.round(comp.relative_center[0]);
                        const relY = Math.round(comp.relative_center[1]);
                        relativeCoordsHtml = `<span style="color: #4CAF50;">(${relX}, ${relY})</span>`;
                    }

                    row.innerHTML = `
                        <td>${index + 1}</td>
                        <td><strong>${comp.class_name || 'Unknown'}</strong></td>
                        <td>(${Math.round(comp.center[0])}, ${Math.round(comp.center[1])})</td>
                        <td>${relativeCoordsHtml}</td>
                        <td>(${Math.round(comp.bbox[0])}, ${Math.round(comp.bbox[1])}, ${Math.round(comp.bbox[2])}, ${Math.round(comp.bbox[3])})</td>
                        <td>${(comp.confidence * 100).toFixed(1)}%</td>
                    `;
                });
            }

            // ROI ìƒíƒœ ìˆ˜ì‹ 
            socket.on('roi_status', (data) => {
                console.log('ğŸ“¥ ROI ìƒíƒœ ìˆ˜ì‹ :', data);

                if (data.camera_id === 'left') {
                    // ê¸°ì¤€ì  ìœ„ì¹˜ ì—…ë°ì´íŠ¸
                    if (data.reference_point) {
                        const [x, y] = data.reference_point;
                        refPointElement.textContent = `(${x}, ${y})`;

                        if (data.status === 'in_roi') {
                            refPointElement.style.color = '#4CAF50';  // ì´ˆë¡ - ROI ì•ˆ
                        } else {
                            refPointElement.style.color = '#FFC107';  // ë…¸ë‘ - ROI ë°–
                        }
                    }
                }
            });

            // YOLO ê²€ì¶œ ê²°ê³¼ ìˆ˜ì‹  (ROI ì•ˆì— ìˆì„ ë•Œë§Œ)
            socket.on('yolo_result', (data) => {
                console.log('ğŸ“¥ YOLO ê²°ê³¼ ìˆ˜ì‹ :', data);

                if (data.camera_id === 'left') {
                    // YOLO ë°•ì‹± ì´ë¯¸ì§€ ì—…ë°ì´íŠ¸
                    if (data.image) {
                        imgElement.src = 'data:image/jpeg;base64,' + data.image;
                        imgElement.style.display = 'block';
                        loadingText.style.display = 'none';
                    }

                    // ë§¤ì¹­ ì‹ ë¢°ë„ ì—…ë°ì´íŠ¸ (YOLO ì‹ ë¢°ë„)
                    if (data.confidence !== undefined) {
                        const conf = (data.confidence * 100).toFixed(2);
                        confidenceElement.textContent = `${conf}%`;

                        // ì‹ ë¢°ë„ì— ë”°ë¼ ìƒ‰ìƒ ë³€ê²½
                        if (data.confidence >= 0.9) {
                            confidenceElement.style.color = '#4CAF50';  // ì´ˆë¡
                        } else if (data.confidence >= 0.7) {
                            confidenceElement.style.color = '#FFC107';  // ë…¸ë‘
                        } else {
                            confidenceElement.style.color = '#ff5555';  // ë¹¨ê°•
                        }
                    }

                    // í…œí”Œë¦¿ í¬ê¸° â†’ YOLO ê²€ì¶œ ê°œìˆ˜ë¡œ ë³€ê²½
                    if (data.boxes_count !== undefined) {
                        templateSizeElement.textContent = `${data.boxes_count}ê°œ`;
                    }

                    // í”„ë ˆì„ í¬ê¸° ì—…ë°ì´íŠ¸
                    if (data.image) {
                        const sizeKB = (data.image.length / 1024).toFixed(1);
                        frameSizeElement.textContent = `${sizeKB} KB`;
                    }
                }
            });

            // ROI ê±´ë„ˆë›°ê¸° ì•Œë¦¼
            socket.on('roi_skipped', (data) => {
                console.log('âš ï¸ YOLO ê±´ë„ˆë›°ê¸°:', data);

                if (data.camera_id === 'left') {
                    confidenceElement.textContent = 'ROI ë°–';
                    confidenceElement.style.color = '#FFC107';
                    templateSizeElement.textContent = '-';
                }
            });

            // ì•Œë¦¼ ë©”ì‹œì§€ í‘œì‹œ í•¨ìˆ˜
            function showNotification(message, type = 'success') {
                notification.textContent = message;
                notification.className = `notification ${type}`;
                notification.style.display = 'block';

                setTimeout(() => {
                    notification.style.display = 'none';
                }, 3000);
            }

            // ê¸°ì¤€ ë¶€í’ˆ ë°°ì¹˜ ì €ì¥ í•¨ìˆ˜
            async function saveReferenceComponents() {
                if (currentComponentsData.length === 0) {
                    showNotification('ê²€ì¶œëœ ì»´í¬ë„ŒíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.', 'error');
                    return;
                }

                // ë²„íŠ¼ ë¹„í™œì„±í™” (ì¤‘ë³µ í´ë¦­ ë°©ì§€)
                saveBtn.disabled = true;
                saveBtn.textContent = 'ğŸ’¾ ì €ì¥ ì¤‘...';

                try {
                    const response = await fetch('/save_reference_components', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify({
                            product_code: 'BC',
                            components: currentComponentsData,
                            tolerance_px: 30.0  // ì¹´ë©”ë¼ ê±°ë¦¬ ì°¨ì´ ê³ ë ¤í•œ í—ˆìš© ì˜¤ì°¨
                        })
                    });

                    const result = await response.json();

                    if (response.ok && result.status === 'ok') {
                        showNotification(`âœ… ${result.message} (${result.components_saved}ê°œ)`, 'success');
                        console.log('âœ… ê¸°ì¤€ ë¶€í’ˆ ë°°ì¹˜ ì €ì¥ ì„±ê³µ:', result);
                    } else {
                        showNotification(`âŒ ì €ì¥ ì‹¤íŒ¨: ${result.error || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}`, 'error');
                        console.error('âŒ ì €ì¥ ì‹¤íŒ¨:', result);
                    }
                } catch (error) {
                    showNotification(`âŒ ì„œë²„ ì˜¤ë¥˜: ${error.message}`, 'error');
                    console.error('âŒ ì„œë²„ ì˜¤ë¥˜:', error);
                } finally {
                    // ë²„íŠ¼ ë‹¤ì‹œ í™œì„±í™”
                    saveBtn.disabled = false;
                    saveBtn.textContent = 'ğŸ’¾ ê¸°ì¤€ ë¶€í’ˆ ë°°ì¹˜ ì €ì¥ (ì œí’ˆ ì½”ë“œ: BC)';
                }
            }

            console.log('âœ… ì‹¤ì‹œê°„ í”„ë ˆì„ ìˆ˜ì‹  ëŒ€ê¸° ì¤‘...');
        </script>
    </body>
    </html>
    """
    return render_template_string(html_template)


@app.route('/video_feed/<camera_id>', methods=['GET'])
def video_feed(camera_id):
    """MJPEG ìŠ¤íŠ¸ë¦¼ ì œê³µ"""
    def generate():
        # ëŒ€ê¸° í™”ë©´ìš© ë”ë¯¸ í”„ë ˆì„ ìƒì„± (íšŒìƒ‰ ë°°ê²½ + í…ìŠ¤íŠ¸)
        dummy_frame = np.zeros((480, 640, 3), dtype=np.uint8)
        dummy_frame[:] = (50, 50, 50)  # ì–´ë‘ìš´ íšŒìƒ‰
        cv2.putText(dummy_frame, f"Waiting for {camera_id} camera...",
                   (100, 240), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)

        while True:
            with frame_lock:
                frame = latest_frames.get(camera_id)

            # í”„ë ˆì„ì´ ì—†ìœ¼ë©´ ë”ë¯¸ í”„ë ˆì„ ì‚¬ìš©
            if frame is None:
                frame = dummy_frame

            # JPEG ì¸ì½”ë”© - Baseline í˜•ì‹ ê°•ì œ (C# Image.FromStream() í˜¸í™˜ì„±)
            encode_params = [
                cv2.IMWRITE_JPEG_QUALITY, 85,        # í™”ì§ˆ 85%
                cv2.IMWRITE_JPEG_PROGRESSIVE, 0,     # Progressive JPEG ë¹„í™œì„±í™” (Baseline ê°•ì œ)
                cv2.IMWRITE_JPEG_OPTIMIZE, 1         # í—ˆí”„ë§Œ í…Œì´ë¸” ìµœì í™”
            ]
            ret, buffer = cv2.imencode('.jpg', frame, encode_params)
            if ret:
                frame_bytes = buffer.tobytes()
                yield (b'--frame\r\n'
                       b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

            time.sleep(0.1)  # 10 FPS (ê¹œë¹¡ê±°ë¦¼ ë°©ì§€)

    return Response(generate(), mimetype='multipart/x-mixed-replace; boundary=frame')




@app.route('/api/latest_results', methods=['GET'])
def get_latest_results():
    """ìµœì‹  ì¶”ë¡  ê²°ê³¼ ë°˜í™˜ (JSON)"""
    with frame_lock:
        results = {
            'left': latest_results.get('left', {}),
            'right': latest_results.get('right', {})
        }
    return jsonify(results)


# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
def crop_to_square(frame, target_size=640):
    """
    í”„ë ˆì„ì„ ì •ì‚¬ê°í˜•ìœ¼ë¡œ ì¤‘ì•™ í¬ë¡­ í›„ ë¦¬ì‚¬ì´ì¦ˆ

    ëŒ€ë¶€ë¶„ì˜ ì›¹ìº ì€ 640x480 (4:3) í•´ìƒë„ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ,
    ì¤‘ì•™ 480x480ì„ í¬ë¡­í•œ í›„ 640x640ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆí•©ë‹ˆë‹¤.

    Args:
        frame: ì…ë ¥ í”„ë ˆì„ (ì˜ˆ: 640x480)
        target_size: ëª©í‘œ í¬ê¸° (ê¸°ë³¸ê°’: 640)

    Returns:
        ì •ì‚¬ê°í˜• í”„ë ˆì„ (target_size x target_size)

    Example:
        640x480 ì…ë ¥ â†’ ì¤‘ì•™ 480x480 í¬ë¡­ â†’ 640x640 ë¦¬ì‚¬ì´ì¦ˆ
        (ì¢Œìš° 80í”½ì…€ì”© ì œê±°)
    """
    height, width = frame.shape[:2]

    # ì´ë¯¸ ì •ì‚¬ê°í˜•ì´ë©´ ê·¸ëŒ€ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
    if height == width:
        if height != target_size:
            return cv2.resize(frame, (target_size, target_size), interpolation=cv2.INTER_LINEAR)
        return frame

    # ì¤‘ì•™ í¬ë¡­ (ì§§ì€ ìª½ ê¸°ì¤€)
    crop_size = min(height, width)

    # ì¤‘ì•™ ì‹œì‘ ìœ„ì¹˜ ê³„ì‚°
    start_x = (width - crop_size) // 2
    start_y = (height - crop_size) // 2

    # í¬ë¡­
    cropped = frame[start_y:start_y + crop_size, start_x:start_x + crop_size]

    # ë¦¬ì‚¬ì´ì¦ˆ
    if crop_size != target_size:
        cropped = cv2.resize(cropped, (target_size, target_size), interpolation=cv2.INTER_LINEAR)

    return cropped


def detect_pcb_roi(frame):
    """
    ì´ˆë¡ìƒ‰ PCB ìë™ ê°ì§€ ë° ë‚´ë¶€ ROI ì¶”ì¶œ

    Args:
        frame: ì›ë³¸ í”„ë ˆì„ (BGR)

    Returns:
        roi_mask: ROI ë§ˆìŠ¤í¬ (255=PCB ë‚´ë¶€, 0=ì™¸ë¶€/í…Œë‘ë¦¬)
        pcb_bbox: PCB ë°”ìš´ë”© ë°•ìŠ¤ (x, y, w, h) ë˜ëŠ” None
        roi_bbox: ROI ë°”ìš´ë”© ë°•ìŠ¤ (x, y, w, h) ë˜ëŠ” None (í…Œë‘ë¦¬ ì œì™¸)
    """
    h, w = frame.shape[:2]

    # 1. HSV ë³€í™˜
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

    # 2. ì´ˆë¡ìƒ‰ PCB ë§ˆìŠ¤í¬ ìƒì„±
    pcb_mask = cv2.inRange(hsv, PCB_COLOR_LOWER_HSV, PCB_COLOR_UPPER_HSV)

    # 3. ë…¸ì´ì¦ˆ ì œê±° (ëª¨í´ë¡œì§€ ì—°ì‚°)
    kernel = np.ones((5, 5), np.uint8)
    pcb_mask = cv2.morphologyEx(pcb_mask, cv2.MORPH_CLOSE, kernel)
    pcb_mask = cv2.morphologyEx(pcb_mask, cv2.MORPH_OPEN, kernel)

    # 4. ê°€ì¥ í° ì»¨íˆ¬ì–´ ì°¾ê¸° (PCB)
    contours, _ = cv2.findContours(pcb_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    if not contours:
        # PCB ê°ì§€ ì‹¤íŒ¨ â†’ ì „ì²´ í”„ë ˆì„ ì‚¬ìš©
        roi_mask = np.ones((h, w), dtype=np.uint8) * 255
        return roi_mask, None, None

    # ê°€ì¥ í° ì»¨íˆ¬ì–´ = PCB
    largest_contour = max(contours, key=cv2.contourArea)
    pcb_x, pcb_y, pcb_w, pcb_h = cv2.boundingRect(largest_contour)

    # 4-1. PCBê°€ í”„ë ˆì„ ê²½ê³„ì— ë¶™ì–´ìˆëŠ”ì§€ í™•ì¸ â­â­â­
    # PCB ì „ì²´ê°€ í”„ë ˆì„ì— ë‚˜ì™€ì•¼ë§Œ ROI ì ìš©
    is_pcb_on_edge = (
        pcb_x < PCB_EDGE_THRESHOLD or  # ì™¼ìª½ ê²½ê³„
        pcb_y < PCB_EDGE_THRESHOLD or  # ìœ„ìª½ ê²½ê³„
        pcb_x + pcb_w > w - PCB_EDGE_THRESHOLD or  # ì˜¤ë¥¸ìª½ ê²½ê³„
        pcb_y + pcb_h > h - PCB_EDGE_THRESHOLD  # ì•„ë˜ìª½ ê²½ê³„
    )

    if is_pcb_on_edge:
        # PCBê°€ í”„ë ˆì„ ê²½ê³„ì— ë¶™ì–´ìˆìŒ â†’ ë¶€ë¶„ì ìœ¼ë¡œë§Œ ë³´ì„ â†’ ì „ì²´ í”„ë ˆì„ ì‚¬ìš©
        roi_mask = np.ones((h, w), dtype=np.uint8) * 255
        return roi_mask, None, None

    # 5. PCB ë‚´ë¶€ ì˜ì—­ë§Œ ROIë¡œ ì„¤ì • (í…Œë‘ë¦¬ ì œì™¸)
    margin_w = int(pcb_w * PCB_INNER_MARGIN_PERCENT)
    margin_h = int(pcb_h * PCB_INNER_MARGIN_PERCENT)

    roi_x = pcb_x + margin_w
    roi_y = pcb_y + margin_h
    roi_w = pcb_w - 2 * margin_w
    roi_h = pcb_h - 2 * margin_h

    # ê²½ê³„ ì²´í¬
    roi_x = max(0, roi_x)
    roi_y = max(0, roi_y)
    roi_w = min(roi_w, w - roi_x)
    roi_h = min(roi_h, h - roi_y)

    # 6. ROI ë§ˆìŠ¤í¬ ìƒì„±
    roi_mask = np.zeros((h, w), dtype=np.uint8)
    roi_mask[roi_y:roi_y+roi_h, roi_x:roi_x+roi_w] = 255

    return roi_mask, (pcb_x, pcb_y, pcb_w, pcb_h), (roi_x, roi_y, roi_w, roi_h)


def detect_motion(current_frame, previous_frame, camera_id):
    """
    í”„ë ˆì„ ì°¨ì´ë¡œ ëª¨ì…˜ ê°ì§€ (ìƒˆ PCB ì§„ì… ê°ì§€)

    Args:
        current_frame: í˜„ì¬ í”„ë ˆì„ (ì»¬ëŸ¬)
        previous_frame: ì´ì „ í”„ë ˆì„ (ì»¬ëŸ¬)
        camera_id: ì¹´ë©”ë¼ ID

    Returns:
        motion_detected: ëª¨ì…˜ ê°ì§€ ì—¬ë¶€
        motion_value: í‰ê·  í”½ì…€ ì°¨ì´
    """
    if previous_frame is None:
        return False, 0.0

    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
    gray_current = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)
    gray_previous = cv2.cvtColor(previous_frame, cv2.COLOR_BGR2GRAY)

    # í”„ë ˆì„ ì°¨ì´ ê³„ì‚°
    frame_diff = cv2.absdiff(gray_current, gray_previous)

    # í‰ê·  ì°¨ì´ ê³„ì‚°
    mean_diff = np.mean(frame_diff)

    # ëª¨ì…˜ ê°ì§€
    motion_detected = mean_diff > MOTION_THRESHOLD

    return motion_detected, mean_diff


def calculate_iou(box1, box2):
    """
    ë‘ ë°”ìš´ë”© ë°•ìŠ¤ì˜ IOU (Intersection over Union) ê³„ì‚°

    Args:
        box1, box2: {'x1': float, 'y1': float, 'x2': float, 'y2': float}

    Returns:
        iou (float): 0.0 ~ 1.0
    """
    # êµì§‘í•© ì˜ì—­ ê³„ì‚°
    x1_inter = max(box1['x1'], box2['x1'])
    y1_inter = max(box1['y1'], box2['y1'])
    x2_inter = min(box1['x2'], box2['x2'])
    y2_inter = min(box1['y2'], box2['y2'])

    # êµì§‘í•© ë©´ì 
    if x2_inter < x1_inter or y2_inter < y1_inter:
        return 0.0

    inter_area = (x2_inter - x1_inter) * (y2_inter - y1_inter)

    # ê° ë°•ìŠ¤ì˜ ë©´ì 
    box1_area = (box1['x2'] - box1['x1']) * (box1['y2'] - box1['y1'])
    box2_area = (box2['x2'] - box2['x1']) * (box2['y2'] - box2['y1'])

    # í•©ì§‘í•© ë©´ì 
    union_area = box1_area + box2_area - inter_area

    if union_area == 0:
        return 0.0

    return inter_area / union_area


def smooth_detections(camera_id, current_detections):
    """
    ê²€ì¶œ ê²°ê³¼ í‰í™œí™” (Temporal Smoothing)

    ì´ì „ í”„ë ˆì„ì˜ ê²€ì¶œ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ì•ˆì •ì ì¸ ê²€ì¶œ ìœ ì§€:
    - ìµœì†Œ MIN_DETECTION_FRAMES í”„ë ˆì„ ë™ì•ˆ ê²€ì¶œëœ ê°ì²´ë§Œ í‘œì‹œ
    - ì‚¬ë¼ì§„ ê°ì²´ëŠ” MAX_MISSING_FRAMES í”„ë ˆì„ ë™ì•ˆ ìœ ì§€

    Args:
        camera_id (str): 'left' or 'right'
        current_detections (list): í˜„ì¬ í”„ë ˆì„ì˜ ê²€ì¶œ ê²°ê³¼ [{...}, {...}]

    Returns:
        smoothed_detections (list): í‰í™œí™”ëœ ê²€ì¶œ ê²°ê³¼
    """
    global next_object_id

    with tracking_lock:
        tracked = tracked_objects[camera_id]

        # í˜„ì¬ ê²€ì¶œ ê²°ê³¼ì™€ ì¶”ì  ì¤‘ì¸ ê°ì²´ ë§¤ì¹­
        matched_ids = set()
        new_detections = []

        for detection in current_detections:
            best_match_id = None
            best_iou = 0.0

            # ì¶”ì  ì¤‘ì¸ ê°ì²´ì™€ ë§¤ì¹­
            for obj_id, tracked_obj in tracked.items():
                iou = calculate_iou(detection, tracked_obj['box'])

                # ê°™ì€ í´ë˜ìŠ¤ì´ë©´ì„œ IOUê°€ ë†’ìœ¼ë©´ ë§¤ì¹­
                if (detection['class_id'] == tracked_obj['class_id'] and
                    iou > IOU_THRESHOLD and
                    iou > best_iou):
                    best_iou = iou
                    best_match_id = obj_id

            if best_match_id is not None:
                # ê¸°ì¡´ ê°ì²´ ì—…ë°ì´íŠ¸
                tracked[best_match_id]['count'] += 1
                tracked[best_match_id]['missing'] = 0

                # 30í”„ë ˆì„ ê²€ì¶œ í›„ ê°’ ê³ ì • (ì»¨ë² ì´ì–´ ë²¨íŠ¸ìš©)
                if not tracked[best_match_id]['frozen']:
                    tracked[best_match_id]['box'] = detection
                    tracked[best_match_id]['confidence'] = detection['confidence']

                    # 30í”„ë ˆì„ ë„ë‹¬ ì‹œ ê³ ì •
                    if tracked[best_match_id]['count'] >= FREEZE_AFTER_FRAMES:
                        tracked[best_match_id]['frozen'] = True
                        logger.info(f"[FREEZE] ê°ì²´ {best_match_id} ê³ ì • ì™„ë£Œ (class: {tracked[best_match_id]['class_name']}, conf: {tracked[best_match_id]['confidence']:.2f})")

                # ì´ë¯¸ ê³ ì •ëœ ê°ì²´ëŠ” boxì™€ confidence ì—…ë°ì´íŠ¸ ì•ˆ í•¨

                matched_ids.add(best_match_id)
            else:
                # ìƒˆë¡œìš´ ê°ì²´ ì¶”ê°€
                new_id = next_object_id
                next_object_id += 1

                tracked[new_id] = {
                    'box': detection,
                    'class_id': detection['class_id'],
                    'class_name': detection['class_name'],
                    'confidence': detection['confidence'],
                    'count': 1,        # ê²€ì¶œ íšŸìˆ˜
                    'missing': 0,      # ë¯¸ê²€ì¶œ íšŸìˆ˜
                    'frozen': False    # 30í”„ë ˆì„ í›„ ê³ ì • ì—¬ë¶€ â­
                }
                matched_ids.add(new_id)

        # ë§¤ì¹­ë˜ì§€ ì•Šì€ ê°ì²´ëŠ” missing ì¹´ìš´íŠ¸ ì¦ê°€
        to_remove = []
        for obj_id in list(tracked.keys()):
            if obj_id not in matched_ids:
                # frozen ê°ì²´ëŠ” ì ˆëŒ€ ì‚­ì œí•˜ì§€ ì•ŠìŒ (ì˜êµ¬ ë³´ì¡´)
                if tracked[obj_id]['frozen']:
                    continue  # missing ì¹´ìš´íŠ¸ë„ ì¦ê°€ ì•ˆ í•¨

                tracked[obj_id]['missing'] += 1

                # MAX_MISSING_FRAMES ì´ˆê³¼ ì‹œ ì œê±° (frozen ì•„ë‹Œ ê°ì²´ë§Œ)
                if tracked[obj_id]['missing'] > MAX_MISSING_FRAMES:
                    to_remove.append(obj_id)

        for obj_id in to_remove:
            del tracked[obj_id]

        # í‰í™œí™”ëœ ê²€ì¶œ ê²°ê³¼ ìƒì„±
        # - Frozen ê°ì²´: ë¬´ì¡°ê±´ í‘œì‹œ (ê³ ì •ëœ ë°•ìŠ¤ëŠ” ì ˆëŒ€ ì‚¬ë¼ì§€ë©´ ì•ˆ ë¨) â­â­â­
        # - ì¼ë°˜ ê°ì²´: MIN_DETECTION_FRAMES ì´ìƒ ê²€ì¶œëœ ê°ì²´ë§Œ í‘œì‹œ
        smoothed = []

        # obj_idë¡œ ì •ë ¬í•˜ì—¬ í•­ìƒ ê°™ì€ ìˆœì„œë¡œ ê·¸ë¦¬ê¸° (ê¹œë¹¡ê±°ë¦¼ ë°©ì§€)
        for obj_id in sorted(tracked.keys()):
            tracked_obj = tracked[obj_id]
            # Frozen ê°ì²´ëŠ” countì™€ ê´€ê³„ì—†ì´ ë¬´ì¡°ê±´ í‘œì‹œ â­
            if tracked_obj['frozen'] or tracked_obj['count'] >= MIN_DETECTION_FRAMES:
                smoothed.append({
                    'x1': tracked_obj['box']['x1'],
                    'y1': tracked_obj['box']['y1'],
                    'x2': tracked_obj['box']['x2'],
                    'y2': tracked_obj['box']['y2'],
                    'confidence': tracked_obj['confidence'],
                    'class_id': tracked_obj['class_id'],
                    'class_name': tracked_obj['class_name']
                })

        # ëª¨ë“  ê°ì²´ê°€ frozen ìƒíƒœì¸ì§€ í™•ì¸ (ì™„ì „ ì •ì§€ ëª¨ë“œ) â­â­â­
        if len(tracked) > 0:
            all_frozen = all(obj['frozen'] for obj in tracked.values())
            # ëª¨ë“  ê°ì²´ frozen + ì¶©ë¶„í•œ ì•ˆì • í”„ë ˆì„ â†’ ì™„ì „ ì •ì§€ ëª¨ë“œ
            if all_frozen and stable_frame_count[camera_id] >= STABLE_FRAMES_FOR_FREEZE and not camera_frozen_state[camera_id]:
                camera_frozen_state[camera_id] = True
                logger.info(f"ğŸ”’ [{camera_id}] ì™„ì „ ì •ì§€ ëª¨ë“œ í™œì„±í™” (ê°ì²´: {len(tracked)}ê°œ, ì•ˆì • í”„ë ˆì„: {stable_frame_count[camera_id]})")

        return smoothed


def draw_bounding_boxes(frame, boxes_data, pcb_bbox=None, roi_bbox=None):
    """
    í”„ë ˆì„ì— ë°”ìš´ë”© ë°•ìŠ¤ ë° ROI ì˜ì—­ ê·¸ë¦¬ê¸°

    Args:
        frame: OpenCV ì´ë¯¸ì§€ (numpy array)
        boxes_data: ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        pcb_bbox: PCB ë°”ìš´ë”© ë°•ìŠ¤ (x, y, w, h) - íŒŒë€ìƒ‰ ì ì„ 
        roi_bbox: ROI ë°”ìš´ë”© ë°•ìŠ¤ (x, y, w, h) - ë…¸ë€ìƒ‰ ì‹¤ì„ 

    Returns:
        annotated_frame: ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€
    """
    annotated_frame = frame.copy()

    # ROI ì˜ì—­ í‘œì‹œ (ë¨¼ì € ê·¸ë ¤ì„œ ë’¤ì— ìˆë„ë¡)
    if pcb_bbox is not None:
        px, py, pw, ph = pcb_bbox
        # PCB ì „ì²´ ì˜ì—­ (íŒŒë€ìƒ‰ ì ì„ )
        cv2.rectangle(annotated_frame, (px, py), (px+pw, py+ph), (255, 0, 0), 2, cv2.LINE_AA)
        cv2.putText(annotated_frame, "PCB", (px+5, py+20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)

    if roi_bbox is not None:
        rx, ry, rw, rh = roi_bbox
        # ROI ë‚´ë¶€ ì˜ì—­ (ë…¸ë€ìƒ‰ ì‹¤ì„ )
        cv2.rectangle(annotated_frame, (rx, ry), (rx+rw, ry+rh), (0, 255, 255), 2, cv2.LINE_AA)
        cv2.putText(annotated_frame, "ROI (Detection Area)", (rx+5, ry+20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

    # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ (12ê°œ í´ë˜ìŠ¤)
    colors = [
        (255, 0, 0),      # Electrolytic capacitor - ë¹¨ê°•
        (0, 255, 0),      # IC - ì´ˆë¡
        (0, 0, 255),      # cds - íŒŒë‘
        (255, 255, 0),    # ceramic capacitor - ë…¸ë‘
        (255, 0, 255),    # diode - ìí™
        (0, 255, 255),    # led - ì²­ë¡
        (128, 0, 0),      # pinheader - ì–´ë‘ìš´ ë¹¨ê°•
        (0, 128, 0),      # pinsocket - ì–´ë‘ìš´ ì´ˆë¡
        (0, 0, 128),      # resistor - ì–´ë‘ìš´ íŒŒë‘
        (128, 128, 0),    # switch - ì˜¬ë¦¬ë¸Œ
        (128, 0, 128),    # transistor - ë³´ë¼
        (0, 128, 128),    # zener diode - ì²­ë¡
    ]

    for box in boxes_data:
        x1 = int(box['x1'])
        y1 = int(box['y1'])
        x2 = int(box['x2'])
        y2 = int(box['y2'])
        conf = box['confidence']
        class_id = box['class_id']
        class_name = box['class_name']

        # ìƒ‰ìƒ ì„ íƒ
        color = colors[class_id % len(colors)]

        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)

        # ë ˆì´ë¸” ë°°ê²½
        label = f"{class_name} {conf:.2f}"
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.5
        thickness = 1
        (text_width, text_height), baseline = cv2.getTextSize(label, font, font_scale, thickness)

        # ë ˆì´ë¸” ë°°ê²½ ê·¸ë¦¬ê¸°
        cv2.rectangle(annotated_frame,
                     (x1, y1 - text_height - 10),
                     (x1 + text_width, y1),
                     color, -1)

        # ë ˆì´ë¸” í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
        cv2.putText(annotated_frame, label,
                   (x1, y1 - 5),
                   font, font_scale, (255, 255, 255), thickness)

    return annotated_frame


def parse_yolo_results(results):
    """
    YOLO ì¶”ë¡  ê²°ê³¼ íŒŒì‹±

    Returns:
        defect_type (str): ë¶ˆëŸ‰ ìœ í˜• ("ì •ìƒ" | "ë¶€í’ˆë¶ˆëŸ‰" | "ë‚©ë•œë¶ˆëŸ‰" | "íê¸°")
        confidence (float): í‰ê·  ì‹ ë¢°ë„ (0.0 ~ 1.0)
        boxes (list): ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    if results is None or len(results) == 0:
        return "ì •ìƒ", 1.0, []

    result = results[0]  # ì²« ë²ˆì§¸ ê²°ê³¼ (ë‹¨ì¼ ì´ë¯¸ì§€)
    boxes_data = []

    # ê²€ì¶œëœ ê°ì²´ê°€ ì—†ìœ¼ë©´ ì •ìƒ
    if result.boxes is None or len(result.boxes) == 0:
        return "ì •ìƒ", 1.0, []

    # ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ ì¶”ì¶œ
    for box in result.boxes:
        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
        conf = float(box.conf[0].cpu().numpy())
        cls = int(box.cls[0].cpu().numpy())
        class_name = result.names[cls]

        boxes_data.append({
            'x1': float(x1),
            'y1': float(y1),
            'x2': float(x2),
            'y2': float(y2),
            'confidence': conf,
            'class_id': cls,
            'class_name': class_name
        })

    # í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
    if boxes_data:
        avg_confidence = sum(b['confidence'] for b in boxes_data) / len(boxes_data)
    else:
        avg_confidence = 1.0

    # ë¶ˆëŸ‰ íŒì • ë¡œì§ (í˜„ì¬ëŠ” ë‹¨ìˆœ ë²„ì „)
    # TODO: ë” ì •êµí•œ íŒì • ë¡œì§ í•„ìš” (ëˆ„ë½ëœ ë¶€í’ˆ, ì˜ëª»ëœ ìœ„ì¹˜ ë“±)
    if len(boxes_data) > 0:
        # ì¼ë‹¨ ê²€ì¶œëœ ê°ì²´ê°€ ìˆìœ¼ë©´ ì •ìƒìœ¼ë¡œ íŒì •
        # í–¥í›„ ê¸°ì¤€ PCBì™€ ë¹„êµí•˜ì—¬ ëˆ„ë½/ì¶”ê°€ ë¶€í’ˆ ê²€ì¶œ í•„ìš”
        defect_type = "ì •ìƒ"
    else:
        defect_type = "ì •ìƒ"

    return defect_type, avg_confidence, boxes_data


def get_gpio_pin(defect_type):
    """ë¶ˆëŸ‰ ìœ í˜•ì— ë”°ë¥¸ GPIO í•€ ë²ˆí˜¸ ë°˜í™˜"""
    gpio_map = {
        'ì •ìƒ': 23,
        'ë¶€í’ˆë¶ˆëŸ‰': 17,
        'ë‚©ë•œë¶ˆëŸ‰': 27,
        'íê¸°': 22
    }
    return gpio_map.get(defect_type, 23)


def defect_type_to_category(defect_type):
    """ë¶ˆëŸ‰ ìœ í˜•ì„ ë°•ìŠ¤ ì¹´í…Œê³ ë¦¬ë¡œ ë³€í™˜"""
    category_map = {
        'ì •ìƒ': 'NORMAL',
        'ë¶€í’ˆë¶ˆëŸ‰': 'COMPONENT_DEFECT',
        'ë‚©ë•œë¶ˆëŸ‰': 'SOLDER_DEFECT',
        'íê¸°': 'DISCARD'
    }
    return category_map.get(defect_type, 'NORMAL')


# ===================================
# SocketIO ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ (WebSocket)
# ===================================

@socketio.on('connect')
def handle_connect():
    """í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì´ë²¤íŠ¸"""
    logger.info(f"[WebSocket] í´ë¼ì´ì–¸íŠ¸ ì—°ê²°: {request.sid}")
    emit('connection_response', {'status': 'connected', 'message': 'Flask SocketIO ì„œë²„ì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤'})


@socketio.on('disconnect')
def handle_disconnect():
    """
    í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ ì´ë²¤íŠ¸
    ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ë° ì†Œì¼“ ëˆ„ìˆ˜ ë°©ì§€ â­
    """
    session_id = request.sid
    logger.info(f"[WebSocket] í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ: {session_id}")

    try:
        # 1. ì„¸ì…˜ ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        # (í•„ìš”ì‹œ ì„¸ì…˜ë³„ ì¶”ì  ë°ì´í„° ì‚­ì œ)

        # 2. threading ëª¨ë“œì—ì„œëŠ” ì†Œì¼“ ì •ë¦¬ ìë™ ì²˜ë¦¬
        # eventlet.sleep(0)  # (eventlet ëª¨ë“œ ì „ìš©, threadingì—ì„œëŠ” ë¶ˆí•„ìš”)

        logger.info(f"[WebSocket] ì„¸ì…˜ {session_id} ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"[WebSocket] disconnect ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)


@socketio.on('request_frame')
def handle_frame_request(data):
    """
    í”„ë ˆì„ ìš”ì²­ ì´ë²¤íŠ¸
    í´ë¼ì´ì–¸íŠ¸ê°€ 100ms ê°„ê²©ìœ¼ë¡œ ìš”ì²­

    Args:
        data (dict): {
            'camera_id': 'left' or 'right',
            'edge_detection': bool (optional),
            'thresholds': {'top': int, 'bottom': int, 'left': int, 'right': int} (optional)
        }
    """
    try:
        camera_id = data.get('camera_id')
        edge_detection = data.get('edge_detection', False)
        thresholds = data.get('thresholds', None)
        rois = data.get('rois', None)

        # DEBUG: ROI íŒŒë¼ë¯¸í„° í™•ì¸ìš© ë¡œê·¸
        logger.info(f"[WebSocket] request_frame ìˆ˜ì‹ : camera={camera_id}, edge={edge_detection}, rois={rois}")

        if camera_id not in ['left', 'right']:
            logger.warning(f"[WebSocket] ì˜ëª»ëœ camera_id: {camera_id}")
            emit('error', {'message': 'Invalid camera_id. Use "left" or "right"'})
            return

        # ìºì‹œëœ JPEG ê°€ì ¸ì˜¤ê¸° (WebSocket ì„±ëŠ¥ ìµœì í™”) â­
        with frame_lock:
            frame_base64 = latest_frames_jpeg.get(camera_id)
            # Edge Detectionì„ ìœ„í•´ ì›ë³¸ í”„ë ˆì„ë„ ê°€ì ¸ì˜¤ê¸°
            original_frame = latest_frames.get(camera_id)

        # ìºì‹œê°€ ì—†ìœ¼ë©´ ë”ë¯¸ í”„ë ˆì„ ìƒì„± ë° ì¸ì½”ë”©
        if frame_base64 is None:
            dummy_frame = np.zeros((640, 640, 3), dtype=np.uint8)
            dummy_frame[:] = (50, 50, 50)  # ì–´ë‘ìš´ íšŒìƒ‰
            cv2.putText(dummy_frame, f"Waiting for {camera_id} camera...",
                       (100, 320), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)

            # ë”ë¯¸ í”„ë ˆì„ JPEG ì¸ì½”ë”©
            encode_params = [
                cv2.IMWRITE_JPEG_QUALITY, 85,
                cv2.IMWRITE_JPEG_PROGRESSIVE, 0,
                cv2.IMWRITE_JPEG_OPTIMIZE, 1
            ]
            ret, buffer = cv2.imencode('.jpg', dummy_frame, encode_params)

            if not ret:
                logger.error(f"[WebSocket] JPEG ì¸ì½”ë”© ì‹¤íŒ¨: {camera_id}")
                emit('error', {'message': 'JPEG encoding failed'})
                return

            frame_base64 = base64.b64encode(buffer.tobytes()).decode('utf-8')
            corners = None
            logger.debug(f"[WebSocket] {camera_id} í”„ë ˆì„ ì—†ìŒ â†’ ë”ë¯¸ í”„ë ˆì„ ì „ì†¡ (640x640)")
        else:
            # Edge Detectionì´ í™œì„±í™”ë˜ê³  ì›ë³¸ í”„ë ˆì„ì´ ìˆìœ¼ë©´ í…Œë‘ë¦¬ ê²€ì¶œ ìˆ˜í–‰
            corners = None
            if edge_detection and original_frame is not None:
                try:
                    # PCB í…Œë‘ë¦¬ ê²€ì¶œ ìˆ˜í–‰
                    detected_corners, debug_img = detect_pcb_edges(
                        original_frame,
                        thresholds=thresholds,
                        rois=rois,
                        draw_debug=True
                    )

                    if detected_corners:
                        corners = detected_corners
                        logger.info(f"[WebSocket] {camera_id} í…Œë‘ë¦¬ ê²€ì¶œ ì„±ê³µ: {len(corners)}ê°œ ì½”ë„ˆ")

                    # ë””ë²„ê·¸ ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì „ì†¡
                    if debug_img is not None:
                        encode_params = [
                            cv2.IMWRITE_JPEG_QUALITY, 85,
                            cv2.IMWRITE_JPEG_PROGRESSIVE, 0,
                            cv2.IMWRITE_JPEG_OPTIMIZE, 1
                        ]
                        ret, buffer = cv2.imencode('.jpg', debug_img, encode_params)
                        if ret:
                            frame_base64 = base64.b64encode(buffer.tobytes()).decode('utf-8')
                            logger.info(f"[WebSocket] {camera_id} í…Œë‘ë¦¬ ê²€ì¶œ ì´ë¯¸ì§€ ì „ì†¡")

                except Exception as e:
                    logger.error(f"[WebSocket] í…Œë‘ë¦¬ ê²€ì¶œ ì‹¤íŒ¨: {e}", exc_info=True)

            logger.debug(f"[WebSocket] {camera_id} ìºì‹œëœ JPEG ì „ì†¡ (ì¸ì½”ë”© ìƒëµ)")

        # ì‘ë‹µ ë°ì´í„° ì¤€ë¹„
        response_data = {
            'camera_id': camera_id,
            'frameData': frame_base64,  # í•„ë“œëª… ë³€ê²½: frame â†’ frameData
            'timestamp': time.time(),
            'size': len(frame_base64)  # Base64 ë¬¸ìì—´ ê¸¸ì´
        }

        # ì½”ë„ˆ ì¢Œí‘œ ì¶”ê°€ (ìˆì„ ê²½ìš°)
        if corners:
            response_data['corners'] = corners

        # NOTE: 'frame' í•„ë“œëª…ì„ 'frameData'ë¡œ ë³€ê²½í•˜ì—¬ Flask-SocketIOì˜ binary ìë™ ë³€í™˜ ë°©ì§€
        emit('frame_data', response_data)

        logger.debug(f"[WebSocket] í”„ë ˆì„ ì „ì†¡ ì™„ë£Œ: {camera_id} ({len(frame_base64)} bytes)")

    except Exception as e:
        logger.error(f"[WebSocket] í”„ë ˆì„ ìš”ì²­ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        emit('error', {'message': f'Frame request failed: {str(e)}'})


@socketio.on('request_template_match')
def handle_template_match_request(data):
    """
    í…œí”Œë¦¿ ë§¤ì¹­ ìš”ì²­ ì´ë²¤íŠ¸

    Args:
        data (dict): {
            'camera_id': 'left' or 'right'
        }
    """
    try:
        camera_id = data.get('camera_id', 'left')
        logger.info(f"[WebSocket] í…œí”Œë¦¿ ë§¤ì¹­ ìš”ì²­: camera={camera_id}")

        # í…œí”Œë¦¿ ì •ë ¬ ì‹œìŠ¤í…œì´ ì—†ìœ¼ë©´ ì—ëŸ¬
        if template_alignment is None:
            logger.error("[WebSocket] í…œí”Œë¦¿ ì •ë ¬ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
            emit('template_match_result', {
                'error': 'Template alignment system not initialized',
                'reference_point': None,
                'confidence': None,
                'image': None,
                'template_size': None,
                'frame_size': None
            })
            return

        # ìºì‹œëœ í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸°
        with frame_lock:
            original_frame = latest_frames.get(camera_id)

        # í”„ë ˆì„ì´ ì—†ìœ¼ë©´ ë”ë¯¸ ë°ì´í„° ì „ì†¡
        if original_frame is None:
            logger.warning(f"[WebSocket] {camera_id} í”„ë ˆì„ ì—†ìŒ â†’ ë”ë¯¸ ì‘ë‹µ")

            # ë”ë¯¸ í”„ë ˆì„ ìƒì„±
            dummy_frame = np.zeros((640, 640, 3), dtype=np.uint8)
            dummy_frame[:] = (50, 50, 50)
            cv2.putText(dummy_frame, f"Waiting for {camera_id} camera...",
                       (100, 320), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)

            encode_params = [cv2.IMWRITE_JPEG_QUALITY, 85]
            ret, buffer = cv2.imencode('.jpg', dummy_frame, encode_params)
            if not ret:
                emit('template_match_result', {'error': 'JPEG encoding failed'})
                return

            frame_base64 = base64.b64encode(buffer.tobytes()).decode('utf-8')

            emit('template_match_result', {
                'reference_point': None,
                'confidence': None,
                'image': frame_base64,
                'template_size': None,
                'frame_size': len(frame_base64)
            })
            return

        # í…œí”Œë¦¿ ë§¤ì¹­ ìˆ˜í–‰
        try:
            # 640x640 ë¦¬ì‚¬ì´ì¦ˆ
            img_resized = cv2.resize(original_frame, (640, 640))

            # ROI ì˜ì—­ ì •ì˜ (ì¤‘ì•™, ì„¸ë¡œë¡œ ê¸¸ê²Œ)
            # 640x640 ì´ë¯¸ì§€ì—ì„œ ì¤‘ì•™ 440px í­, ì „ì²´ ë†’ì´ì˜ 90%
            img_h, img_w = img_resized.shape[:2]
            roi_width = 440  # ì¤‘ì•™ 440px í­ (40px ì¶”ê°€ ì¦ê°€)
            roi_height_margin = 30  # ìƒí•˜ ê° 30px ì—¬ìœ 

            roi_x1 = (img_w - roi_width) // 2  # (640 - 440) / 2 = 100
            roi_x2 = roi_x1 + roi_width  # 100 + 440 = 540
            roi_y1 = roi_height_margin  # 30
            roi_y2 = img_h - roi_height_margin  # 640 - 30 = 610

            roi = (roi_x1, roi_y1, roi_x2, roi_y2)
            logger.info(f"[WebSocket] ROI ì˜ì—­: x={roi_x1}~{roi_x2}, y={roi_y1}~{roi_y2}")

            # ê¸°ì¤€ì  ì°¾ê¸° (ROI ê²€ì¦ ì—†ì´ ë¨¼ì € í…œí”Œë¦¿ ë§¤ì¹­)
            reference_point = template_alignment.find_reference_point(
                img_resized,
                method=cv2.TM_CCORR_NORMED,
                roi=None  # ROI ê²€ì¦ ë¹„í™œì„±í™” (ì‹œê°í™”ìš©)
            )

            if reference_point:
                # ROI ê²€ì¦ (ê²½ê³ ë§Œ, ê±°ë¶€í•˜ì§€ ì•ŠìŒ)
                ref_x, ref_y = reference_point
                is_in_roi = (roi_x1 <= ref_x <= roi_x2 and roi_y1 <= ref_y <= roi_y2)

                if not is_in_roi:
                    logger.warning(f"[WebSocket] âš ï¸ ê¸°ì¤€ì ì´ ROI ë°–: ({ref_x}, {ref_y}), ROI=({roi_x1}, {roi_y1}, {roi_x2}, {roi_y2})")
                else:
                    logger.info(f"[WebSocket] âœ… ê¸°ì¤€ì ì´ ROI ì•ˆ: ({ref_x}, {ref_y})")

                # ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± (ROIë„ í‘œì‹œ)
                vis_img = template_alignment.visualize_reference_point(
                    img_resized,
                    reference_point,
                    roi=roi
                )

                # í…œí”Œë¦¿ ì˜ì—­ë„ í‘œì‹œ
                template_h, template_w = template_alignment.template.shape[:2]
                top_left_x = ref_x - template_w // 2
                top_left_y = ref_y - template_h // 2

                cv2.rectangle(
                    vis_img,
                    (top_left_x, top_left_y),
                    (top_left_x + template_w, top_left_y + template_h),
                    (255, 0, 255),  # ë³´ë¼ìƒ‰
                    3
                )

                # ROI ì•ˆì— ìˆì„ ë•Œë§Œ YOLO ê²€ì¶œ ìˆ˜í–‰
                yolo_detected_count = 0
                if is_in_roi and yolo_model is not None:
                    logger.info("[WebSocket] ğŸ¯ ROI ì•ˆì— ìˆìŒ - YOLO ê²€ì¶œ ì‹œì‘")

                    # YOLO ì¶”ë¡ 
                    yolo_results = yolo_model.predict(img_resized, conf=0.25, verbose=False)

                    if len(yolo_results) > 0 and len(yolo_results[0].boxes) > 0:
                        boxes = yolo_results[0].boxes
                        yolo_detected_count = len(boxes)
                        logger.info(f"[WebSocket] âœ… YOLO ê²€ì¶œ ì™„ë£Œ: {yolo_detected_count}ê°œ ë¶€í’ˆ")

                        # YOLO ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                        for box in boxes:
                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                            conf = box.conf[0].cpu().numpy()
                            cls = int(box.cls[0].cpu().numpy())

                            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ì´ˆë¡ìƒ‰)
                            cv2.rectangle(
                                vis_img,
                                (int(x1), int(y1)),
                                (int(x2), int(y2)),
                                (0, 255, 0),  # ì´ˆë¡ìƒ‰
                                2
                            )

                            # í´ë˜ìŠ¤ì™€ ì‹ ë¢°ë„ í‘œì‹œ
                            label = f"Class {cls}: {conf:.2f}"
                            cv2.putText(
                                vis_img,
                                label,
                                (int(x1), int(y1) - 5),
                                cv2.FONT_HERSHEY_SIMPLEX,
                                0.5,
                                (0, 255, 0),
                                1
                            )
                    else:
                        logger.info("[WebSocket] â„¹ï¸ YOLO ê²€ì¶œ ê²°ê³¼ ì—†ìŒ")

                # ROI ìƒíƒœ í…ìŠ¤íŠ¸ ì¶”ê°€
                if is_in_roi:
                    if yolo_detected_count > 0:
                        status_text = f"âœ… IN ROI - {yolo_detected_count} COMPONENTS DETECTED"
                    else:
                        status_text = "âœ… IN ROI - NO DETECTION"
                    status_color = (0, 255, 0)
                else:
                    status_text = "âš ï¸ OUT OF ROI - YOLO SKIPPED"
                    status_color = (0, 0, 255)

                cv2.putText(
                    vis_img,
                    status_text,
                    (10, img_h - 10),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.8,
                    status_color,
                    2
                )

                # ë§¤ì¹­ ì‹ ë¢°ë„ ê³„ì‚°
                gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)
                template_gray = cv2.cvtColor(template_alignment.template, cv2.COLOR_BGR2GRAY)
                result = cv2.matchTemplate(gray, template_gray, cv2.TM_CCORR_NORMED)
                min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)
                confidence = max_val

                logger.info(f"[WebSocket] í…œí”Œë¦¿ ë§¤ì¹­ ì„±ê³µ: ref={reference_point}, conf={confidence:.4f}")

                # ì´ë¯¸ì§€ ì¸ì½”ë”©
                encode_params = [cv2.IMWRITE_JPEG_QUALITY, 85]
                ret, buffer = cv2.imencode('.jpg', vis_img, encode_params)
                if not ret:
                    logger.error("[WebSocket] JPEG ì¸ì½”ë”© ì‹¤íŒ¨")
                    emit('template_match_result', {'error': 'JPEG encoding failed'})
                    return

                frame_base64 = base64.b64encode(buffer.tobytes()).decode('utf-8')

                # ì‘ë‹µ ì „ì†¡
                emit('template_match_result', {
                    'reference_point': [int(ref_x), int(ref_y)],
                    'confidence': float(confidence),
                    'image': frame_base64,
                    'template_size': [int(template_w), int(template_h)],
                    'frame_size': len(frame_base64)
                })
            else:
                # í…œí”Œë¦¿ ë§¤ì¹­ ì‹¤íŒ¨
                logger.warning("[WebSocket] í…œí”Œë¦¿ ë§¤ì¹­ ì‹¤íŒ¨ (ê¸°ì¤€ì  ê²€ì¶œ ì‹¤íŒ¨)")

                # ì›ë³¸ ì´ë¯¸ì§€ë§Œ ì „ì†¡
                encode_params = [cv2.IMWRITE_JPEG_QUALITY, 85]
                ret, buffer = cv2.imencode('.jpg', img_resized, encode_params)
                if ret:
                    frame_base64 = base64.b64encode(buffer.tobytes()).decode('utf-8')
                    emit('template_match_result', {
                        'reference_point': None,
                        'confidence': None,
                        'image': frame_base64,
                        'template_size': None,
                        'frame_size': len(frame_base64)
                    })
                else:
                    emit('template_match_result', {'error': 'JPEG encoding failed'})

        except Exception as e:
            logger.error(f"[WebSocket] í…œí”Œë¦¿ ë§¤ì¹­ ì‹¤íŒ¨: {e}", exc_info=True)
            emit('template_match_result', {'error': str(e)})

    except Exception as e:
        logger.error(f"[WebSocket] í…œí”Œë¦¿ ë§¤ì¹­ ìš”ì²­ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        emit('error', {'message': f'Template match request failed: {str(e)}'})


if __name__ == '__main__':
    logger.info("Flask ì¶”ë¡  ì„œë²„ ì‹œì‘ (SocketIO + threading í™œì„±í™”)...")
    logger.info("í¬íŠ¸: 5000")
    logger.info("í˜¸ìŠ¤íŠ¸: 0.0.0.0 (ëª¨ë“  ì¸í„°í˜ì´ìŠ¤)")
    logger.info("WebSocket ì—”ë“œí¬ì¸íŠ¸: ws://0.0.0.0:5000/socket.io/")
    logger.info("ë¹„ë™ê¸° ëª¨ë“œ: threading (YOLO/OpenCV ì•ˆì •ì„± ìš°ì„ ) â­")

    # SocketIOë¡œ ì‹¤í–‰ (threading ì„œë²„ ì‚¬ìš©)
    socketio.run(
        app,
        host='0.0.0.0',  # ì™¸ë¶€ ì ‘ê·¼ í—ˆìš©
        port=5000,
        debug=False,     # í”„ë¡œë•ì…˜ ëª¨ë“œ
        use_reloader=False,  # ìë™ ì¬ì‹œì‘ ë¹„í™œì„±í™” (í”„ë¡œë•ì…˜)
        log_output=True,  # ë¡œê·¸ ì¶œë ¥ í™œì„±í™”
        allow_unsafe_werkzeug=True  # Werkzeug í”„ë¡œë•ì…˜ ê²½ê³  ë¬´ì‹œ (threading ëª¨ë“œ)
    )
